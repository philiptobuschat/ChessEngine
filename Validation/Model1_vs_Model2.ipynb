{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import sys, os\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.append(project_root)\n",
    "\n",
    "from Resources.Model import Model_v4\n",
    "from Resources.Game import *\n",
    "from Resources.TS_ModelGuided import *\n",
    "from Resources.TS_ModelGuided_MCRollout import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Setup Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1 = Model_v4()\n",
    "model_1.eval()\n",
    "model_1.load_state_dict(torch.load('../Train Value Function/Monte Carlo/Model Saves MC v4/model_51410_games'))\n",
    "\n",
    "model_2 = Model_v4()\n",
    "model_2.eval()\n",
    "model_2.load_state_dict(torch.load('../Train Value Function/Monte Carlo/Model Saves MC v4/model_51410_games'))\n",
    "\n",
    "# model2 = Model_v4()\n",
    "# model2.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_test_games = 100\n",
    "\n",
    "# strategies = ['one step greedy', 'TS', 'TS with rollout']\n",
    "\n",
    "strategy_1 = 'one step greedy'\n",
    "strategy_2 = 'TS'\n",
    "\n",
    "tmax_1 = 1 # seconds of tree search per move, if applies\n",
    "tmax_2 = 10 # seconds of tree search per move, if applies\n",
    "\n",
    "wins_1 = 0\n",
    "wins_2 = 0\n",
    "draws  = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -- 0 -- winner: white\n",
      " -- 1 -- winner: black\n",
      " -- 2 -- winner: black\n",
      " -- 3 -- winner: black\n",
      " -- 4 -- winner: black\n",
      " -- 5 -- winner: draw\n",
      " -- 6 -- winner: black\n",
      " -- 7 -- winner: white\n",
      " -- 8 -- winner: draw\n",
      " -- 9 -- winner: black\n",
      " -- 10 -- winner: black\n",
      " -- 11 -- winner: draw\n",
      " -- 12 -- winner: draw\n",
      " -- 13 -- winner: black\n",
      " -- 14 -- winner: black\n",
      " -- 15 -- winner: black\n",
      " -- 16 -- winner: white\n",
      " -- 17 -- winner: draw\n",
      " -- 18 -- winner: white\n",
      " -- 19 -- winner: black\n",
      " -- 20 -- winner: black\n",
      " -- 21 -- winner: draw\n",
      " -- 22 -- winner: black\n",
      " -- 23 -- winner: draw\n",
      " -- 24 -- winner: draw\n",
      " -- 25 -- winner: black\n",
      " -- 26 -- winner: black\n",
      " -- 27 -- winner: white\n",
      " -- 28 -- winner: black\n",
      " -- 29 -- winner: black\n",
      " -- 30 -- winner: draw\n",
      " -- 31 -- winner: white\n",
      " -- 32 -- winner: black\n",
      " -- 33 -- winner: black\n",
      " -- 34 -- winner: white\n",
      " -- 35 -- winner: black\n",
      " -- 36 -- winner: white\n",
      " -- 37 -- winner: black\n",
      " -- 38 -- winner: white\n",
      " -- 39 -- winner: draw\n",
      " -- 40 -- winner: draw\n",
      " -- 41 -- winner: white\n",
      " -- 42 -- winner: draw\n",
      " -- 43 -- winner: white\n",
      " -- 44 -- winner: black\n",
      " -- 45 -- winner: black\n",
      " -- 46 -- winner: draw\n",
      " -- 47 -- winner: white\n",
      " -- 48 -- winner: black\n",
      " -- 49 -- winner: black\n",
      " -- 50 -- winner: white\n",
      " -- 51 -- winner: black\n",
      " -- 52 -- winner: white\n",
      " -- 53 -- winner: draw\n",
      " -- 54 -- winner: black\n",
      " -- 55 -- winner: black\n",
      " -- 56 -- winner: white\n",
      " -- 57 -- winner: black\n",
      " -- 58 -- winner: black\n",
      " -- 59 -- winner: white\n",
      " -- 60 -- winner: black\n",
      " -- 61 -- winner: black\n",
      " -- 62 -- winner: draw\n",
      " -- 63 -- winner: draw\n",
      " -- 64 -- winner: white\n",
      " -- 65 -- winner: black\n",
      " -- 66 -- winner: white\n",
      " -- 67 -- winner: draw\n",
      " -- 68 -- winner: black\n",
      " -- 69 -- winner: draw\n",
      " -- 70 -- winner: black\n",
      " -- 71 -- winner: draw\n",
      " -- 72 -- winner: draw\n",
      " -- 73 -- winner: draw\n",
      " -- 74 -- winner: draw\n",
      " -- 75 -- winner: white\n",
      " -- 76 -- winner: black\n",
      " -- 77 -- winner: black\n",
      " -- 78 -- winner: white\n",
      " -- 79 -- winner: black\n",
      " -- 80 -- winner: draw\n",
      " -- 81 -- winner: black\n",
      " -- 82 -- winner: draw\n",
      " -- 83 -- winner: white\n",
      " -- 84 -- winner: white\n",
      " -- 85 -- winner: black\n",
      " -- 86 -- winner: black\n",
      " -- 87 -- winner: black\n",
      " -- 88 -- winner: white\n",
      " -- 89 -- winner: black\n",
      " -- 90 -- winner: black\n",
      " -- 91 -- winner: black\n",
      " -- 92 -- winner: black\n",
      " -- 93 -- winner: white\n",
      " -- 94 -- winner: draw\n",
      " -- 95 -- winner: white\n",
      " -- 96 -- winner: black\n",
      " -- 97 -- winner: draw\n",
      " -- 98 -- winner: black\n",
      " -- 99 -- winner: black\n",
      "\n",
      "final statistics:\n",
      "wins 1: 65, draws: 26, wins 2: 9\n"
     ]
    }
   ],
   "source": [
    "for i_test_game in range(n_test_games): # loop through test games\n",
    "\n",
    "    game = Game()\n",
    "    i = 0\n",
    "\n",
    "    color_choice = np.random.choice([True, False])\n",
    "\n",
    "    if color_choice:\n",
    "        color_1 = 'white'\n",
    "        color_2 = 'black'\n",
    "    else:\n",
    "        color_1 = 'black'\n",
    "        color_2 = 'white'\n",
    "\n",
    "    value_list_1 = []\n",
    "    value_list_2 = []\n",
    "\n",
    "    while not game.is_over(): # loop through moves in current test game\n",
    "\n",
    "        if game.turn == color_1:\n",
    "            model_curr      = model_1\n",
    "            strategy_curr   = strategy_1\n",
    "            if 'TS' in strategy_curr:\n",
    "                tmax_curr   = tmax_1\n",
    "        else:\n",
    "            model_curr      = model_2\n",
    "            strategy_curr   = strategy_2\n",
    "            if 'TS' in strategy_curr:\n",
    "                tmax_curr   = tmax_2\n",
    "\n",
    "        if strategy_curr == 'one step greedy':\n",
    "\n",
    "            # play move that achieves highest value given current model\n",
    "            # except: if a move checkmates, always chose that move\n",
    "\n",
    "            moves = game.PossibleMoves()\n",
    "            game_ini = game.copy()\n",
    "            board_batch = []\n",
    "\n",
    "            mate = False\n",
    "            for move in moves:\n",
    "                game.PlayMove(move)\n",
    "                board_batch.append(board_to_tensor(game.pieces))\n",
    "                game.FlipBoard()\n",
    "                if game.is_over():\n",
    "                    if game.get_winner() != 'draw':\n",
    "                        mate = True\n",
    "                        chosen_move = move\n",
    "                        game = game_ini.copy()\n",
    "                        break\n",
    "                game = game_ini.copy()\n",
    "\n",
    "            if not mate:\n",
    "                \n",
    "                board_tensor = torch.stack(board_batch)\n",
    "\n",
    "                if i < 11: # in early phase of game, chose move stochastically to avoid repeating games\n",
    "                    values = model_curr(board_tensor)\n",
    "                    values_diff = [10*(values[i] - torch.mean(values)) for i in range(0, len(values))]\n",
    "                    move_prob = torch.softmax(torch.Tensor(values_diff), dim=0).numpy()\n",
    "                    chosen_i = np.random.choice(range(len(moves)), p=move_prob)\n",
    "                    chosen_move = moves[chosen_i]\n",
    "\n",
    "                else:\n",
    "                    values = model_curr(board_tensor).detach().numpy()\n",
    "                    chosen_move = moves[np.argmax(values)]\n",
    "\n",
    "            if game.turn == color_1:\n",
    "                value_list_1.append(max(values))\n",
    "            if game.turn == color_2:\n",
    "                value_list_2.append(max(values))\n",
    "\n",
    "        elif strategy_curr == 'TS':\n",
    "\n",
    "            chosen_move, root = ModelGuided_TS(game, model_curr, root=None, tmax=tmax_curr, prints=False)\n",
    "\n",
    "        elif strategy_curr == 'TS with rollout':\n",
    "\n",
    "            chosen_move, root = MC_TS(game, model_curr, root=None, tmax=tmax_curr, prints=False)\n",
    "\n",
    "        game.PlayMove(chosen_move)\n",
    "        game.FlipBoard()\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    winner = game.get_winner()\n",
    "\n",
    "    if winner == color_1:\n",
    "        wins_1 += 1\n",
    "        print('win 1')\n",
    "    elif winner == color_2:\n",
    "        wins_2 += 1\n",
    "        print('win 2')\n",
    "    elif winner == 'draw':\n",
    "        draws += 1\n",
    "        print('draw')\n",
    "\n",
    "    print(' -- {} -- winner: {}'.format(i_test_game, winner))\n",
    "\n",
    "print()\n",
    "print('final statistics:')\n",
    "print('wins 1: {}, draws: {}, wins 2: {}'.format(wins_1, draws, wins_2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "MC (51410) one step greedy  vs  MC (51410) one step greedy\n",
    "    wins 1: 312, draws: 420, wins 2: 303\n",
    "\n",
    "MC (51410) one step greedy  vs  untrained one step greedy\n",
    "    wins 1: 828, draws: 113, wins 2: 59\n",
    "\n",
    "MC (51410) one step greedy  vs MC (51410) TS (10s)\n",
    "    wins 1: 65, draws: 26, wins 2: 9\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
