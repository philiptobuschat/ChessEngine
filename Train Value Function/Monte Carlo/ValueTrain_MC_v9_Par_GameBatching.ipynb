{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import sys, os\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "sys.path.append(project_root)\n",
    "\n",
    "from Resources.Model import Model_v9\n",
    "from Resources.Game import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### global parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 0.98\n",
    "value_diff_scale = 250\n",
    "value_diff_scale_early = 5\n",
    "# games saved in batches to reduce i/o stream\n",
    "# each batch is a input file and a label file containing [batch_size] individual games\n",
    "batch_size = 400"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### local counters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "white_wins = 0\n",
    "black_wins = 0\n",
    "draws = 0\n",
    "\n",
    "game_count = 0          # counting decisive games\n",
    "batch_count = 0         # number of batches locally done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i = 0, with 400 active games \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i = 5, with 400 active games \n",
      "i = 10, with 397 active games \n",
      "i = 15, with 391 active games \n",
      "i = 20, with 387 active games \n",
      "i = 25, with 383 active games \n",
      "i = 30, with 380 active games \n",
      "i = 35, with 375 active games \n",
      "i = 40, with 370 active games \n",
      "i = 45, with 363 active games \n",
      "i = 50, with 358 active games \n",
      "i = 55, with 351 active games \n",
      "i = 60, with 343 active games \n",
      "i = 65, with 334 active games \n",
      "i = 70, with 324 active games \n",
      "i = 75, with 314 active games \n",
      "i = 80, with 306 active games \n",
      "i = 85, with 292 active games \n",
      "i = 90, with 276 active games \n",
      "i = 95, with 260 active games \n",
      "i = 100, with 247 active games \n",
      "i = 105, with 232 active games \n",
      "i = 110, with 218 active games \n",
      "i = 115, with 211 active games \n",
      "i = 120, with 193 active games \n",
      "i = 125, with 180 active games \n",
      "i = 130, with 162 active games \n",
      "i = 135, with 140 active games \n",
      "i = 140, with 126 active games \n",
      "i = 145, with 106 active games \n",
      "i = 150, with 86 active games \n",
      "i = 155, with 74 active games \n",
      "i = 160, with 59 active games \n",
      "i = 165, with 49 active games \n",
      "i = 170, with 40 active games \n",
      "i = 175, with 33 active games \n",
      "i = 180, with 26 active games \n",
      "i = 185, with 16 active games \n",
      "i = 190, with 10 active games \n",
      "i = 195, with 7 active games \n",
      "i = 200, with 7 active games \n",
      "i = 205, with 4 active games \n",
      "i = 210, with 3 active games \n",
      "i = 215, with 3 active games \n",
      "i = 220, with 2 active games \n",
      "i = 225, with 2 active games \n",
      "i = 230, with 2 active games \n",
      "i = 235, with 2 active games \n",
      "i = 240, with 1 active games \n",
      "batch of 400 had 132 decisive games\n",
      "total time =  545.6931428909302\n",
      "with 132 decisive games\n"
     ]
    }
   ],
   "source": [
    "first_load = True\n",
    "initialize_batch = True\n",
    "\n",
    "batch_white_wins = 0\n",
    "batch_black_wins = 0\n",
    "batch_draws = 0\n",
    "\n",
    "while True:\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    # load newest model initially and for every new batch\n",
    "    if initialize_batch or first_load:\n",
    "        model = Model_v9()\n",
    "        model_saves = os.listdir('../Monte Carlo/Model Saves MC v9')\n",
    "        if len(model_saves) > 0:\n",
    "            newest_model = max(int(i[6:-8]) for i in model_saves)\n",
    "            model.load_state_dict(torch.load('../Monte Carlo/Model Saves MC v9/model_{}_batches'.format(newest_model)))\n",
    "\n",
    "        first_load = False\n",
    "\n",
    "    meta_games = []\n",
    "    meta_boards_white = []; meta_boards_black = []\n",
    "    i = 0\n",
    "\n",
    "    meta_active = []\n",
    "\n",
    "    for game_ind in range(batch_size):\n",
    "        meta_games.append( Game() )\n",
    "        meta_boards_white.append([]); meta_boards_black.append([])\n",
    "        meta_active.append(True)\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    while True in meta_active:\n",
    "\n",
    "        if i % 5 == 0:\n",
    "            print('i = {}, with {} active games '.format(i, meta_active.count(True)))\n",
    "\n",
    "        i += 1\n",
    "        full_board_batch = []\n",
    "        meta_board_batch_sizes = [] # save batch sizes to split model output afterwards\n",
    "\n",
    "        meta_moves = []\n",
    "\n",
    "        # go through games, collect positions for value evaluations\n",
    "\n",
    "        for g, game in enumerate(meta_games):\n",
    "\n",
    "            if not meta_active[g]:\n",
    "                meta_board_batch_sizes.append(0)\n",
    "                meta_moves.append([])\n",
    "                continue\n",
    "\n",
    "            meta_moves.append(game.PossibleMoves())\n",
    "\n",
    "            game_ini = game.copy()\n",
    "            board_batch = [board_to_tensor(game.pieces)]\n",
    "\n",
    "            mate = False\n",
    "\n",
    "            for move in meta_moves[-1]:\n",
    "                game.PlayMove(move)\n",
    "                board_batch.append(board_to_tensor(game.pieces))\n",
    "                game.FlipBoard()\n",
    "                if game.is_over():\n",
    "                    mate = True\n",
    "                    break\n",
    "                game = game_ini.copy()\n",
    "\n",
    "            meta_games[g] = game.copy()\n",
    "\n",
    "            if mate:\n",
    "                # print('mate move found')\n",
    "                meta_active[g] = False\n",
    "                meta_board_batch_sizes.append(0)\n",
    "\n",
    "                game.FlipBoard()\n",
    "\n",
    "                if i % 2 == 1:\n",
    "                    meta_boards_white[g].append(board_to_bool_tensor(game.pieces))\n",
    "                if i % 2 == 0:\n",
    "                    meta_boards_black[g].append(board_to_bool_tensor(game.pieces))\n",
    "\n",
    "            if not mate:\n",
    "                full_board_batch = full_board_batch + board_batch\n",
    "                meta_board_batch_sizes.append(len(board_batch))\n",
    "\n",
    "        if len(full_board_batch) == 0:\n",
    "            break\n",
    "\n",
    "        # get values of all positions\n",
    "\n",
    "        full_board_batch = torch.stack(full_board_batch)\n",
    "        out = model(full_board_batch).detach()\n",
    "        meta_values = torch.split(out, meta_board_batch_sizes)\n",
    "\n",
    "        # make moves for all games\n",
    "\n",
    "        for g, game in enumerate(meta_games):\n",
    "\n",
    "            # if not (6 in game.pieces and 16 in game.pieces):\n",
    "            #     print('king lost old round 1')\n",
    "\n",
    "            if not meta_active[g]:\n",
    "                continue\n",
    "\n",
    "            values = meta_values[g]\n",
    "\n",
    "            if i < 7:\n",
    "                scale = value_diff_scale_early\n",
    "            else:\n",
    "                scale = value_diff_scale\n",
    "            values_diff = [scale*(values[i] - values[0]) for i in range(1, len(values))]\n",
    "            move_prob = torch.softmax(torch.Tensor(values_diff), dim=0).numpy()\n",
    "            chosen_i = np.random.choice(range(len(meta_moves[g])), p=move_prob)\n",
    "            chosen_move = meta_moves[g][chosen_i]\n",
    "\n",
    "            # if not (6 in game.pieces and 16 in game.pieces):\n",
    "            #     print('king lost old round 2')\n",
    "\n",
    "            game.PlayMove(chosen_move)\n",
    "\n",
    "            if i % 2 == 1:\n",
    "                meta_boards_white[g].append(board_to_bool_tensor(game.pieces))\n",
    "            if i % 2 == 0:\n",
    "                meta_boards_black[g].append(board_to_bool_tensor(game.pieces))\n",
    "\n",
    "            game.FlipBoard()\n",
    "\n",
    "            # if not (6 in game.pieces and 16 in game.pieces):\n",
    "            #     print('king lost old round 3')\n",
    "\n",
    "    meta_inputs = []\n",
    "    meta_labels = []\n",
    "\n",
    "    for g, game in enumerate(meta_games):\n",
    "        \n",
    "        winner = game.get_winner()\n",
    "\n",
    "        if winner == 'draw':\n",
    "            draws += 1; batch_draws += 1\n",
    "            continue\n",
    "            reward_white = 0;   reward_black = 0\n",
    "\n",
    "        elif winner == 'white':\n",
    "            white_wins += 1; batch_white_wins += 1\n",
    "            reward_white = 1;   reward_black = -1\n",
    "\n",
    "        elif winner == 'black':\n",
    "            black_wins += 1; batch_black_wins += 1\n",
    "            reward_white = -1;  reward_black = 1\n",
    "\n",
    "        labels_white = [reward_white * gamma**(len(meta_boards_white[g]) - 1 - i) for i in range(len(meta_boards_white[g]))]\n",
    "        labels_black = [reward_black * gamma**(len(meta_boards_black[g]) - 1 - i) for i in range(len(meta_boards_black[g]))]\n",
    "\n",
    "        meta_inputs = meta_inputs + meta_boards_white[g] + meta_boards_black[g]\n",
    "        meta_labels = meta_labels + labels_white + labels_black\n",
    "\n",
    "    if batch_white_wins + batch_black_wins == 0:\n",
    "        print('skip')\n",
    "        continue\n",
    "\n",
    "    inputs_tens = torch.stack(meta_inputs)\n",
    "    labels_tens = torch.Tensor(meta_labels)\n",
    "\n",
    "    print('batch of {} had {} decisive games'.format(batch_size, batch_white_wins + batch_black_wins))\n",
    "\n",
    "    batch_count += 1\n",
    "\n",
    "    print('total time = ', time.time() - t0)\n",
    "    print('with {} decisive games'.format(white_wins + black_wins))\n",
    "\n",
    "    break\n",
    "\n",
    "    continue\n",
    "\n",
    "    with open('/Users/Philip/Desktop/Projects/RL Chess/MCTS/Game Saves v9/stats', 'rb') as f:\n",
    "        stats = torch.load(f)\n",
    "    stats = stats.int()\n",
    "    stats[0] += 1 # batch index\n",
    "    stats[1] += batch_white_wins\n",
    "    stats[2] += batch_black_wins\n",
    "    stats[3] += batch_draws\n",
    "    torch.save(stats, '/Users/Philip/Desktop/Projects/RL Chess/MCTS/Game Saves v9/stats')\n",
    "\n",
    "    # print('update index ', stats[0])\n",
    "\n",
    "    new_batch_index = stats[0]\n",
    "\n",
    "    print('time: ', time.time() - t0)\n",
    "\n",
    "    # torch.save(inputs_tens, '/Users/Philip/Desktop/Projects/RL Chess/MCTS/Game Saves v9/inputs_{}'.format(new_batch_index))\n",
    "    # torch.save(labels_tens, '/Users/Philip/Desktop/Projects/RL Chess/MCTS/Game Saves v9/labels_{}'.format(new_batch_index))\n",
    "\n",
    "    print('local batches: {} --  w: {}, b: {}, d: {}'.format(batch_count, white_wins, black_wins, draws))\n",
    "\n",
    "    if batch_count % 5 == 0:\n",
    "        print(' -- global batches = {} --  w: {}, b: {}, d: {} (total: {})'.format(\n",
    "            new_batch_index, stats[1], stats[2], stats[3], stats[1] + stats[2] + stats[3]))\n",
    "\n",
    "    initialize_batch = True\n",
    "\n",
    "    batch_white_wins = 0\n",
    "    batch_black_wins = 0\n",
    "    batch_draws = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total time =  1112.3149409294128\n",
      "with 290 decisive games\n"
     ]
    }
   ],
   "source": [
    "# Test duration of game old way\n",
    "\n",
    "n_games = 400\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "for i_game in range(n_games):\n",
    "\n",
    "    game = Game()\n",
    "    i = 0\n",
    "    boards_white = [];  boards_black = []\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    while not game.is_over():\n",
    "        \n",
    "        i += 1\n",
    "        moves = game.PossibleMoves()\n",
    "\n",
    "        game_ini = game.copy()\n",
    "        board_batch = [board_to_tensor(game.pieces)]\n",
    "\n",
    "        mate = False\n",
    "\n",
    "        for move in moves:\n",
    "            game.PlayMove(move)\n",
    "            board_batch.append(board_to_tensor(game.pieces))\n",
    "            game.FlipBoard()\n",
    "            if game.is_over():\n",
    "                mate = True\n",
    "                chosen_move = move\n",
    "                game = game_ini.copy()\n",
    "                break\n",
    "            game = game_ini.copy()\n",
    "\n",
    "        if not mate:\n",
    "            board_tensor = torch.stack(board_batch)\n",
    "            values = model(board_tensor)\n",
    "            if i < 7:\n",
    "                scale = value_diff_scale_early\n",
    "            else:\n",
    "                scale = value_diff_scale\n",
    "            values_diff = [scale*(values[i] - values[0]) for i in range(1, len(values))]\n",
    "            move_prob = torch.softmax(torch.Tensor(values_diff), dim=0).numpy()\n",
    "            chosen_i = np.random.choice(range(len(moves)), p=move_prob)\n",
    "            chosen_move = moves[chosen_i]\n",
    "            \n",
    "        game.PlayMove(chosen_move)\n",
    "\n",
    "        if i % 2 == 1:\n",
    "            boards_white.append(board_to_bool_tensor(game.pieces))\n",
    "        if i % 2 == 0:\n",
    "            boards_black.append(board_to_bool_tensor(game.pieces))\n",
    "\n",
    "        game.FlipBoard()\n",
    "    \n",
    "    winner = game.get_winner()\n",
    "\n",
    "    if winner == 'draw':\n",
    "        draws += 1; batch_draws += 1\n",
    "        continue\n",
    "        reward_white = 0;   reward_black = 0\n",
    "\n",
    "    elif winner == 'white':\n",
    "        white_wins += 1; batch_white_wins += 1\n",
    "        reward_white = 1;   reward_black = -1\n",
    "\n",
    "    elif winner == 'black':\n",
    "        black_wins += 1; batch_black_wins += 1\n",
    "        reward_white = -1;  reward_black = 1\n",
    "\n",
    "    labels_white = [reward_white * gamma**(len(boards_white) - 1 - i) for i in range(len(boards_white))]\n",
    "    labels_black = [reward_black * gamma**(len(boards_black) - 1 - i) for i in range(len(boards_black))]\n",
    "\n",
    "    inputs_tens = torch.stack(boards_white + boards_black)\n",
    "    labels_tens = torch.Tensor(labels_white + labels_black)\n",
    "\n",
    "    if initialize_batch:\n",
    "        batch_inputs = inputs_tens.clone()\n",
    "        batch_labels = labels_tens.clone()\n",
    "        initialize_batch = False\n",
    "    else:\n",
    "        batch_inputs = torch.cat((batch_inputs, inputs_tens))\n",
    "        batch_labels = torch.cat((batch_labels, labels_tens))\n",
    "\n",
    "    game_count += 1\n",
    "\n",
    "print('total time = ', time.time() - t0)\n",
    "print('with {} decisive games'.format(white_wins + black_wins))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "510\n"
     ]
    }
   ],
   "source": [
    "print(draws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model_v9:\n",
    "# 100 consecutive games: 337.908s (34 draws, 66 decisive)\n",
    "# 100 parallel games: 151.934s \n",
    "# 400 parallel games: 545.693s batch of 400 had 132 decisive games\n",
    "# 400 consecutive games: 1112.315s (158 decisive )\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
