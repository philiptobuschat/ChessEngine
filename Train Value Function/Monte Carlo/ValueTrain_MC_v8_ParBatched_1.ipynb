{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import sys, os\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "sys.path.append(project_root)\n",
    "\n",
    "from Resources.Model import Model_v8\n",
    "from Resources.Game import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### global parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 0.98\n",
    "value_diff_scale = 50\n",
    "value_diff_scale_early = 1\n",
    "# games saved in batches to reduce i/o stream\n",
    "# each batch is a input file and a label file containing [batch_size] individual games\n",
    "batch_target = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### local counters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "white_wins = 0\n",
    "black_wins = 0\n",
    "draws = 0\n",
    "\n",
    "batch_count = 0         # number of batches locally done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local batches: 1 --  w: 99, b: 94, d: 307\n",
      "local batches: 2 --  w: 148, b: 145, d: 457\n",
      "local batches: 3 --  w: 192, b: 192, d: 616\n",
      "local batches: 4 --  w: 246, b: 238, d: 766\n",
      " -- global batches = 1232 --  w: 61478, b: 61698, d: 185734 (total: 308910)\n",
      "local batches: 5 --  w: 298, b: 306, d: 896\n",
      "local batches: 6 --  w: 353, b: 363, d: 1034\n",
      "local batches: 7 --  w: 415, b: 409, d: 1176\n",
      "local batches: 8 --  w: 472, b: 468, d: 1310\n",
      "local batches: 9 --  w: 538, b: 509, d: 1453\n",
      " -- global batches = 1257 --  w: 62833, b: 63045, d: 189282 (total: 315160)\n",
      "local batches: 10 --  w: 591, b: 560, d: 1599\n",
      "local batches: 11 --  w: 639, b: 614, d: 1747\n",
      "local batches: 12 --  w: 692, b: 660, d: 1898\n",
      "local batches: 13 --  w: 768, b: 701, d: 2031\n",
      "local batches: 14 --  w: 826, b: 759, d: 2165\n",
      " -- global batches = 1282 --  w: 64263, b: 64274, d: 192873 (total: 321410)\n",
      "local batches: 15 --  w: 880, b: 811, d: 2309\n",
      "local batches: 16 --  w: 930, b: 858, d: 2461\n",
      "local batches: 17 --  w: 963, b: 910, d: 2625\n",
      "local batches: 18 --  w: 1008, b: 968, d: 2771\n",
      "local batches: 19 --  w: 1058, b: 1017, d: 2921\n",
      " -- global batches = 1309 --  w: 65743, b: 65616, d: 196780 (total: 328139)\n",
      "local batches: 20 --  w: 1109, b: 1076, d: 3060\n",
      "local batches: 21 --  w: 1156, b: 1132, d: 3206\n",
      "local batches: 22 --  w: 1212, b: 1175, d: 3356\n",
      "local batches: 23 --  w: 1265, b: 1218, d: 3509\n",
      "local batches: 24 --  w: 1311, b: 1271, d: 3659\n",
      " -- global batches = 1334 --  w: 67079, b: 66810, d: 200475 (total: 334364)\n",
      "local batches: 25 --  w: 1369, b: 1306, d: 3815\n",
      "local batches: 26 --  w: 1429, b: 1348, d: 3962\n",
      "local batches: 27 --  w: 1474, b: 1396, d: 4118\n",
      "local batches: 28 --  w: 1523, b: 1437, d: 4277\n",
      "local batches: 29 --  w: 1577, b: 1483, d: 4426\n",
      " -- global batches = 1360 --  w: 68391, b: 67969, d: 204478 (total: 340838)\n",
      "local batches: 30 --  w: 1637, b: 1541, d: 4557\n",
      "local batches: 31 --  w: 1690, b: 1587, d: 4707\n",
      "local batches: 32 --  w: 1731, b: 1632, d: 4870\n",
      "local batches: 33 --  w: 1788, b: 1683, d: 5011\n",
      "local batches: 34 --  w: 1849, b: 1724, d: 5158\n",
      " -- global batches = 1385 --  w: 69706, b: 69144, d: 208213 (total: 347063)\n",
      "local batches: 35 --  w: 1897, b: 1781, d: 5302\n",
      "local batches: 36 --  w: 1953, b: 1831, d: 5445\n",
      "local batches: 37 --  w: 2004, b: 1882, d: 5592\n",
      "local batches: 38 --  w: 2058, b: 1929, d: 5740\n",
      "local batches: 39 --  w: 2115, b: 1980, d: 5881\n",
      " -- global batches = 1409 --  w: 70932, b: 70381, d: 211726 (total: 353039)\n",
      "local batches: 40 --  w: 2169, b: 2033, d: 6023\n",
      "local batches: 41 --  w: 2213, b: 2085, d: 6176\n",
      "local batches: 42 --  w: 2268, b: 2134, d: 6321\n",
      "local batches: 43 --  w: 2320, b: 2188, d: 6464\n",
      "local batches: 44 --  w: 2370, b: 2238, d: 6613\n",
      " -- global batches = 1434 --  w: 72205, b: 71623, d: 215436 (total: 359264)\n",
      "local batches: 45 --  w: 2414, b: 2293, d: 6763\n",
      "local batches: 46 --  w: 2460, b: 2333, d: 6926\n",
      "local batches: 47 --  w: 2517, b: 2372, d: 7079\n",
      "local batches: 48 --  w: 2570, b: 2423, d: 7224\n",
      "local batches: 49 --  w: 2603, b: 2467, d: 7396\n",
      " -- global batches = 1460 --  w: 73546, b: 72923, d: 219269 (total: 365738)\n",
      "local batches: 50 --  w: 2661, b: 2505, d: 7549\n",
      "local batches: 51 --  w: 2707, b: 2553, d: 7704\n",
      "local batches: 52 --  w: 2750, b: 2598, d: 7865\n",
      "local batches: 53 --  w: 2804, b: 2647, d: 8011\n",
      "local batches: 54 --  w: 2853, b: 2701, d: 8157\n",
      " -- global batches = 1485 --  w: 74878, b: 74159, d: 222926 (total: 371963)\n",
      "local batches: 55 --  w: 2899, b: 2751, d: 8310\n",
      "local batches: 56 --  w: 2955, b: 2808, d: 8446\n",
      "local batches: 57 --  w: 3012, b: 2868, d: 8578\n",
      "local batches: 58 --  w: 3071, b: 2918, d: 8718\n",
      "local batches: 59 --  w: 3119, b: 2976, d: 8861\n",
      " -- global batches = 1510 --  w: 76211, b: 75442, d: 226535 (total: 378188)\n",
      "local batches: 60 --  w: 3166, b: 3026, d: 9013\n",
      "local batches: 61 --  w: 3222, b: 3081, d: 9151\n",
      "local batches: 62 --  w: 3290, b: 3132, d: 9281\n",
      "local batches: 63 --  w: 3345, b: 3184, d: 9423\n",
      "local batches: 64 --  w: 3400, b: 3238, d: 9563\n",
      " -- global batches = 1535 --  w: 77602, b: 76768, d: 230043 (total: 384413)\n",
      "local batches: 65 --  w: 3457, b: 3282, d: 9711\n",
      "local batches: 66 --  w: 3516, b: 3333, d: 9849\n",
      "local batches: 67 --  w: 3573, b: 3375, d: 9998\n",
      "local batches: 68 --  w: 3620, b: 3409, d: 10165\n",
      "local batches: 69 --  w: 3673, b: 3479, d: 10291\n",
      " -- global batches = 1561 --  w: 78924, b: 78061, d: 233886 (total: 390871)\n",
      "local batches: 70 --  w: 3723, b: 3542, d: 10426\n",
      "local batches: 71 --  w: 3771, b: 3586, d: 10582\n",
      "local batches: 72 --  w: 3822, b: 3646, d: 10719\n",
      "local batches: 73 --  w: 3869, b: 3706, d: 10860\n",
      "local batches: 74 --  w: 3916, b: 3771, d: 10996\n",
      " -- global batches = 1586 --  w: 80132, b: 79364, d: 237579 (total: 397075)\n",
      "local batches: 75 --  w: 3959, b: 3821, d: 11151\n",
      "local batches: 76 --  w: 4004, b: 3874, d: 11301\n",
      "local batches: 77 --  w: 4049, b: 3919, d: 11459\n",
      "local batches: 78 --  w: 4103, b: 3967, d: 11606\n",
      "local batches: 79 --  w: 4146, b: 4013, d: 11765\n",
      " -- global batches = 1612 --  w: 81416, b: 80650, d: 241462 (total: 403528)\n",
      "local batches: 80 --  w: 4193, b: 4065, d: 11914\n",
      "local batches: 81 --  w: 4254, b: 4114, d: 12052\n",
      "local batches: 82 --  w: 4311, b: 4179, d: 12178\n",
      "local batches: 83 --  w: 4363, b: 4228, d: 12325\n",
      "local batches: 84 --  w: 4409, b: 4291, d: 12464\n",
      " -- global batches = 1637 --  w: 82729, b: 82132, d: 244867 (total: 409728)\n",
      "local batches: 85 --  w: 4453, b: 4343, d: 12616\n",
      "local batches: 86 --  w: 4496, b: 4405, d: 12759\n",
      "local batches: 87 --  w: 4551, b: 4469, d: 12888\n",
      "local batches: 88 --  w: 4599, b: 4524, d: 13033\n",
      "local batches: 89 --  w: 4646, b: 4572, d: 13186\n",
      " -- global batches = 1662 --  w: 84013, b: 83579, d: 248336 (total: 415928)\n",
      "local batches: 90 --  w: 4701, b: 4619, d: 13332\n",
      "local batches: 91 --  w: 4749, b: 4679, d: 13472\n",
      "local batches: 92 --  w: 4806, b: 4730, d: 13612\n",
      "local batches: 93 --  w: 4846, b: 4785, d: 13765\n",
      "local batches: 94 --  w: 4892, b: 4847, d: 13905\n",
      " -- global batches = 1686 --  w: 85185, b: 84917, d: 251778 (total: 421880)\n",
      "local batches: 95 --  w: 4935, b: 4918, d: 14039\n",
      "local batches: 96 --  w: 4993, b: 4978, d: 14168\n",
      "local batches: 97 --  w: 5035, b: 5039, d: 14312\n",
      "local batches: 98 --  w: 5091, b: 5101, d: 14441\n",
      "local batches: 99 --  w: 5149, b: 5155, d: 14576\n",
      " -- global batches = 1711 --  w: 86513, b: 86291, d: 255258 (total: 428062)\n",
      "local batches: 100 --  w: 5194, b: 5209, d: 14724\n",
      "local batches: 101 --  w: 5251, b: 5260, d: 14863\n",
      "local batches: 102 --  w: 5301, b: 5320, d: 15000\n",
      "local batches: 103 --  w: 5357, b: 5373, d: 15138\n",
      "local batches: 104 --  w: 5413, b: 5427, d: 15275\n",
      " -- global batches = 1736 --  w: 87794, b: 87689, d: 258754 (total: 434237)\n",
      "local batches: 105 --  w: 5486, b: 5472, d: 15404\n",
      "local batches: 106 --  w: 5545, b: 5512, d: 15552\n",
      "local batches: 107 --  w: 5588, b: 5570, d: 15698\n",
      "local batches: 108 --  w: 5644, b: 5611, d: 15848\n",
      "local batches: 109 --  w: 5693, b: 5665, d: 15992\n",
      " -- global batches = 1762 --  w: 89215, b: 89093, d: 262351 (total: 440659)\n",
      "local batches: 110 --  w: 5756, b: 5723, d: 16118\n",
      "local batches: 111 --  w: 5796, b: 5782, d: 16266\n",
      "local batches: 112 --  w: 5853, b: 5848, d: 16390\n",
      "local batches: 113 --  w: 5896, b: 5902, d: 16539\n",
      "local batches: 114 --  w: 5940, b: 5954, d: 16689\n",
      " -- global batches = 1787 --  w: 90433, b: 90523, d: 265867 (total: 446823)\n",
      "local batches: 115 --  w: 5981, b: 6028, d: 16820\n",
      "local batches: 116 --  w: 6027, b: 6082, d: 16966\n",
      "local batches: 117 --  w: 6090, b: 6132, d: 17099\n",
      "local batches: 118 --  w: 6147, b: 6191, d: 17229\n",
      "local batches: 119 --  w: 6201, b: 6243, d: 17369\n",
      " -- global batches = 1812 --  w: 91777, b: 91947, d: 269249 (total: 452973)\n",
      "local batches: 120 --  w: 6254, b: 6298, d: 17507\n",
      "local batches: 121 --  w: 6298, b: 6367, d: 17640\n",
      "local batches: 122 --  w: 6351, b: 6430, d: 17770\n",
      "local batches: 123 --  w: 6399, b: 6485, d: 17913\n",
      "local batches: 124 --  w: 6453, b: 6540, d: 18050\n",
      " -- global batches = 1838 --  w: 93234, b: 93434, d: 272701 (total: 459369)\n",
      "local batches: 125 --  w: 6510, b: 6592, d: 18187\n",
      "local batches: 126 --  w: 6566, b: 6651, d: 18317\n",
      "local batches: 127 --  w: 6614, b: 6714, d: 18451\n",
      "local batches: 128 --  w: 6670, b: 6758, d: 18596\n",
      "local batches: 129 --  w: 6717, b: 6811, d: 18741\n",
      " -- global batches = 1864 --  w: 94656, b: 94865, d: 276227 (total: 465748)\n",
      "local batches: 130 --  w: 6770, b: 6858, d: 18886\n",
      "local batches: 131 --  w: 6835, b: 6911, d: 19013\n",
      "local batches: 132 --  w: 6894, b: 6950, d: 19160\n",
      "local batches: 133 --  w: 6942, b: 7010, d: 19297\n",
      "local batches: 134 --  w: 6994, b: 7060, d: 19440\n",
      " -- global batches = 1889 --  w: 96070, b: 96168, d: 279635 (total: 471873)\n",
      "local batches: 135 --  w: 7042, b: 7114, d: 19583\n",
      "local batches: 136 --  w: 7097, b: 7172, d: 19715\n",
      "local batches: 137 --  w: 7144, b: 7230, d: 19855\n",
      "local batches: 138 --  w: 7185, b: 7288, d: 20001\n",
      "local batches: 139 --  w: 7238, b: 7342, d: 20139\n",
      " -- global batches = 1915 --  w: 97410, b: 97584, d: 283249 (total: 478243)\n",
      "local batches: 140 --  w: 7287, b: 7403, d: 20274\n",
      "local batches: 141 --  w: 7341, b: 7455, d: 20413\n",
      "local batches: 142 --  w: 7398, b: 7520, d: 20536\n",
      "local batches: 143 --  w: 7457, b: 7574, d: 20668\n",
      "local batches: 144 --  w: 7520, b: 7628, d: 20796\n",
      " -- global batches = 1940 --  w: 98826, b: 98910, d: 286632 (total: 484368)\n",
      "local batches: 145 --  w: 7577, b: 7682, d: 20929\n",
      "local batches: 146 --  w: 7640, b: 7738, d: 21054\n",
      "local batches: 147 --  w: 7699, b: 7796, d: 21181\n",
      "local batches: 148 --  w: 7760, b: 7851, d: 21309\n",
      "local batches: 149 --  w: 7820, b: 7901, d: 21443\n",
      " -- global batches = 1965 --  w: 100266, b: 100289, d: 289915 (total: 490470)\n",
      "local batches: 150 --  w: 7884, b: 7972, d: 21552\n",
      "local batches: 151 --  w: 7937, b: 8031, d: 21684\n",
      "local batches: 152 --  w: 7990, b: 8080, d: 21826\n",
      "local batches: 153 --  w: 8039, b: 8136, d: 21965\n",
      "local batches: 154 --  w: 8094, b: 8189, d: 22101\n",
      " -- global batches = 1990 --  w: 101704, b: 101738, d: 293128 (total: 496570)\n",
      "local batches: 155 --  w: 8141, b: 8246, d: 22241\n",
      "local batches: 156 --  w: 8200, b: 8299, d: 22372\n",
      "local batches: 157 --  w: 8256, b: 8350, d: 22508\n",
      "local batches: 158 --  w: 8298, b: 8407, d: 22652\n",
      "local batches: 159 --  w: 8354, b: 8458, d: 22788\n",
      " -- global batches = 2015 --  w: 103192, b: 103111, d: 296349 (total: 502652)\n",
      "local batches: 160 --  w: 8408, b: 8518, d: 22917\n",
      "local batches: 161 --  w: 8463, b: 8580, d: 23043\n",
      "local batches: 162 --  w: 8528, b: 8620, d: 23181\n",
      "local batches: 163 --  w: 8580, b: 8679, d: 23313\n",
      "local batches: 164 --  w: 8627, b: 8733, d: 23455\n",
      " -- global batches = 2040 --  w: 104600, b: 104474, d: 299653 (total: 508727)\n",
      "local batches: 165 --  w: 8700, b: 8785, d: 23573\n",
      "local batches: 166 --  w: 8758, b: 8833, d: 23710\n",
      "local batches: 167 --  w: 8809, b: 8874, d: 23861\n",
      "local batches: 168 --  w: 8866, b: 8921, d: 24000\n",
      "local batches: 169 --  w: 8928, b: 8962, d: 24140\n",
      " -- global batches = 2065 --  w: 105948, b: 105797, d: 303057 (total: 514802)\n",
      "local batches: 170 --  w: 9004, b: 8999, d: 24270\n",
      "local batches: 171 --  w: 9054, b: 9059, d: 24403\n",
      "local batches: 172 --  w: 9112, b: 9126, d: 24520\n",
      "local batches: 173 --  w: 9175, b: 9191, d: 24634\n",
      "local batches: 174 --  w: 9223, b: 9250, d: 24769\n",
      " -- global batches = 2090 --  w: 107441, b: 107173, d: 306251 (total: 520865)\n",
      "local batches: 175 --  w: 9276, b: 9308, d: 24900\n",
      "local batches: 176 --  w: 9330, b: 9351, d: 25045\n",
      "local batches: 177 --  w: 9377, b: 9402, d: 25189\n",
      "local batches: 178 --  w: 9444, b: 9461, d: 25305\n",
      "local batches: 179 --  w: 9492, b: 9521, d: 25439\n",
      " -- global batches = 2115 --  w: 108770, b: 108510, d: 309635 (total: 526915)\n",
      "local batches: 180 --  w: 9542, b: 9586, d: 25566\n",
      "local batches: 181 --  w: 9608, b: 9635, d: 25693\n",
      "local batches: 182 --  w: 9654, b: 9682, d: 25842\n",
      "local batches: 183 --  w: 9704, b: 9729, d: 25987\n",
      "local batches: 184 --  w: 9763, b: 9781, d: 26118\n",
      " -- global batches = 2140 --  w: 110146, b: 109835, d: 312984 (total: 532965)\n",
      "local batches: 185 --  w: 9823, b: 9821, d: 26260\n",
      "local batches: 186 --  w: 9886, b: 9874, d: 26386\n",
      "local batches: 187 --  w: 9935, b: 9920, d: 26533\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/Philip/Desktop/GitHub/ChessEngine/Train Value Function/Monte Carlo/ValueTrain_MC_v8_ParBatched_1.ipynb Cell 6\u001b[0m line \u001b[0;36m6\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Philip/Desktop/GitHub/ChessEngine/Train%20Value%20Function/Monte%20Carlo/ValueTrain_MC_v8_ParBatched_1.ipynb#X15sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m \u001b[39mfor\u001b[39;00m move \u001b[39min\u001b[39;00m meta_moves[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Philip/Desktop/GitHub/ChessEngine/Train%20Value%20Function/Monte%20Carlo/ValueTrain_MC_v8_ParBatched_1.ipynb#X15sZmlsZQ%3D%3D?line=67'>68</a>\u001b[0m     game\u001b[39m.\u001b[39mPlayMove(move)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/Philip/Desktop/GitHub/ChessEngine/Train%20Value%20Function/Monte%20Carlo/ValueTrain_MC_v8_ParBatched_1.ipynb#X15sZmlsZQ%3D%3D?line=68'>69</a>\u001b[0m     board_batch\u001b[39m.\u001b[39mappend(board_to_tensor(game\u001b[39m.\u001b[39;49mpieces))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Philip/Desktop/GitHub/ChessEngine/Train%20Value%20Function/Monte%20Carlo/ValueTrain_MC_v8_ParBatched_1.ipynb#X15sZmlsZQ%3D%3D?line=69'>70</a>\u001b[0m     game\u001b[39m.\u001b[39mFlipBoard()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Philip/Desktop/GitHub/ChessEngine/Train%20Value%20Function/Monte%20Carlo/ValueTrain_MC_v8_ParBatched_1.ipynb#X15sZmlsZQ%3D%3D?line=70'>71</a>\u001b[0m     \u001b[39mif\u001b[39;00m game\u001b[39m.\u001b[39mis_over():\n",
      "File \u001b[0;32m~/Desktop/GitHub/ChessEngine/Resources/Game.py:2127\u001b[0m, in \u001b[0;36mboard_to_tensor\u001b[0;34m(board)\u001b[0m\n\u001b[1;32m   2125\u001b[0m     tensor[i, :] \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mfrom_numpy((board \u001b[39m==\u001b[39m i\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mastype(\u001b[39m'\u001b[39m\u001b[39muint8\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[1;32m   2126\u001b[0m     \u001b[39m# black pieces channel\u001b[39;00m\n\u001b[0;32m-> 2127\u001b[0m     tensor[i\u001b[39m+\u001b[39m\u001b[39m6\u001b[39m, :] \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mfrom_numpy((board \u001b[39m==\u001b[39;49m i\u001b[39m+\u001b[39;49m\u001b[39m11\u001b[39;49m)\u001b[39m.\u001b[39;49mastype(\u001b[39m'\u001b[39;49m\u001b[39muint8\u001b[39;49m\u001b[39m'\u001b[39;49m))\n\u001b[1;32m   2129\u001b[0m \u001b[39mreturn\u001b[39;00m tensor\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# keep generating new batches of data until stopped\n",
    "while True:\n",
    "\n",
    "    batch_white_wins = 0\n",
    "    batch_black_wins = 0\n",
    "    batch_draws = 0\n",
    "\n",
    "    # load newest model\n",
    "    model = Model_v8()\n",
    "    model_saves = os.listdir('../Monte Carlo/Model Saves MC v8_3')\n",
    "    if len(model_saves) > 0:\n",
    "        newest_model = max(int(i[6:-8]) for i in model_saves)\n",
    "        model.load_state_dict(torch.load('../Monte Carlo/Model Saves MC v8_3/model_{}_batches'.format(newest_model)))\n",
    "    else:\n",
    "        time.sleep(0.05)\n",
    "\n",
    "    # print('loaded model ', newest_model)\n",
    "\n",
    "    with open('/Users/Philip/Desktop/Projects/RL Chess/MCTS/Game Saves v8_3/stats', 'rb') as f:\n",
    "        stats = torch.load(f)\n",
    "    stats = stats.int()\n",
    "    global_white_wins   = stats[1]\n",
    "    global_black_wins   = stats[2]\n",
    "    global_draws        = stats[3]\n",
    "\n",
    "    percentage_decisive = (global_white_wins + global_black_wins) / (global_white_wins + global_black_wins + global_draws)\n",
    "    batch_size = int(batch_target // percentage_decisive.item()) # so that on average we have [batch_target] decisive games\n",
    "\n",
    "    meta_games = []\n",
    "    meta_boards_white = []; meta_boards_black = []\n",
    "    i = 0\n",
    "\n",
    "    meta_active = []\n",
    "\n",
    "    for game_ind in range(batch_size):\n",
    "        meta_games.append( Game() )\n",
    "        meta_boards_white.append([]); meta_boards_black.append([])\n",
    "        meta_active.append(True)\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    # print('start with {} games'.format(batch_size))\n",
    "\n",
    "    while True in meta_active:\n",
    "\n",
    "        # if i % 20 == 0:\n",
    "        #     print('i = {}, with {} active games '.format(i, meta_active.count(True)))\n",
    "\n",
    "        i += 1\n",
    "        full_board_batch = []\n",
    "        meta_board_batch_sizes = [] # save batch sizes to split model output afterwards\n",
    "        meta_moves = []\n",
    "\n",
    "        # go through games, collect positions for value evaluations\n",
    "        for g, game in enumerate(meta_games):\n",
    "\n",
    "            if not meta_active[g]:\n",
    "                meta_board_batch_sizes.append(0)\n",
    "                meta_moves.append([])\n",
    "                continue\n",
    "\n",
    "            meta_moves.append(game.PossibleMoves())\n",
    "            game_ini = game.copy()\n",
    "            board_batch = [board_to_tensor(game.pieces)]\n",
    "            mate = False\n",
    "\n",
    "            for move in meta_moves[-1]:\n",
    "                game.PlayMove(move)\n",
    "                board_batch.append(board_to_tensor(game.pieces))\n",
    "                game.FlipBoard()\n",
    "                if game.is_over():\n",
    "                    mate = True\n",
    "                    break\n",
    "                game = game_ini.copy()\n",
    "\n",
    "            meta_games[g] = game.copy()\n",
    "\n",
    "            if mate:\n",
    "                meta_active[g] = False\n",
    "                meta_board_batch_sizes.append(0)\n",
    "                game.FlipBoard()\n",
    "                if i % 2 == 1:\n",
    "                    meta_boards_white[g].append(board_to_bool_tensor(game.pieces))\n",
    "                if i % 2 == 0:\n",
    "                    meta_boards_black[g].append(board_to_bool_tensor(game.pieces))\n",
    "\n",
    "            if not mate:\n",
    "                full_board_batch = full_board_batch + board_batch\n",
    "                meta_board_batch_sizes.append(len(board_batch))\n",
    "\n",
    "        if len(full_board_batch) == 0:\n",
    "            break\n",
    "\n",
    "        # get values of all positions\n",
    "        full_board_batch = torch.stack(full_board_batch)\n",
    "        out = model(full_board_batch).detach()\n",
    "        meta_values = torch.split(out, meta_board_batch_sizes)\n",
    "\n",
    "        # make moves for all games\n",
    "        for g, game in enumerate(meta_games):\n",
    "\n",
    "            if not meta_active[g]:\n",
    "                continue\n",
    "            values = meta_values[g]\n",
    "            if i < 7:\n",
    "                scale = value_diff_scale_early\n",
    "            else:\n",
    "                scale = value_diff_scale\n",
    "            values_diff = [scale*(values[i] - values[0]) for i in range(1, len(values))]\n",
    "            move_prob = torch.softmax(torch.Tensor(values_diff), dim=0).numpy()\n",
    "            chosen_i = np.random.choice(range(len(meta_moves[g])), p=move_prob)\n",
    "            chosen_move = meta_moves[g][chosen_i]\n",
    "            game.PlayMove(chosen_move)\n",
    "            if i % 2 == 1:\n",
    "                meta_boards_white[g].append(board_to_bool_tensor(game.pieces))\n",
    "            if i % 2 == 0:\n",
    "                meta_boards_black[g].append(board_to_bool_tensor(game.pieces))\n",
    "            game.FlipBoard()\n",
    "\n",
    "    # print('games done, start evaluating')\n",
    "\n",
    "    meta_inputs = []\n",
    "    meta_labels = []\n",
    "\n",
    "    for g, game in enumerate(meta_games):\n",
    "        \n",
    "        winner = game.get_winner()\n",
    "        if winner == 'draw':\n",
    "            draws += 1; batch_draws += 1\n",
    "            continue\n",
    "            reward_white = 0;   reward_black = 0\n",
    "\n",
    "        elif winner == 'white':\n",
    "            white_wins += 1; batch_white_wins += 1\n",
    "            reward_white = 1;   reward_black = -1\n",
    "\n",
    "        elif winner == 'black':\n",
    "            black_wins += 1; batch_black_wins += 1\n",
    "            reward_white = -1;  reward_black = 1\n",
    "\n",
    "        labels_white = [reward_white * gamma**(len(meta_boards_white[g]) - 1 - i) for i in range(len(meta_boards_white[g]))]\n",
    "        labels_black = [reward_black * gamma**(len(meta_boards_black[g]) - 1 - i) for i in range(len(meta_boards_black[g]))]\n",
    "\n",
    "        meta_inputs = meta_inputs + meta_boards_white[g] + meta_boards_black[g]\n",
    "        meta_labels = meta_labels + labels_white + labels_black\n",
    "\n",
    "    if batch_white_wins + batch_black_wins == 0:\n",
    "        print('no decisive games in the whole batch -> skip to next batch (batch size too small?)')\n",
    "        continue\n",
    "\n",
    "    inputs_tens = torch.stack(meta_inputs)\n",
    "    labels_tens = torch.Tensor(meta_labels)\n",
    "\n",
    "    # print('evaluation done, save batch')\n",
    "\n",
    "    with open('/Users/Philip/Desktop/Projects/RL Chess/MCTS/Game Saves v8_3/stats', 'rb') as f:\n",
    "        stats = torch.load(f)\n",
    "    stats = stats.int()\n",
    "    stats[0] += 1;                  stats[1] += batch_white_wins\n",
    "    stats[2] += batch_black_wins;   stats[3] += batch_draws\n",
    "    torch.save(stats, '/Users/Philip/Desktop/Projects/RL Chess/MCTS/Game Saves v8_3/stats')\n",
    "\n",
    "    # print('batch index = ', stats[0])\n",
    "\n",
    "    new_batch_index = stats[0]\n",
    "    torch.save(inputs_tens, '/Users/Philip/Desktop/Projects/RL Chess/MCTS/Game Saves v8_3/inputs_{}'.format(new_batch_index))\n",
    "    torch.save(labels_tens, '/Users/Philip/Desktop/Projects/RL Chess/MCTS/Game Saves v8_3/labels_{}'.format(new_batch_index))\n",
    "\n",
    "    print('local batches: {} --  w: {}, b: {}, d: {}'.format(batch_count, white_wins, black_wins, draws))\n",
    "\n",
    "    batch_count += 1\n",
    "\n",
    "    if batch_count % 5 == 0:\n",
    "        print(' -- global batches = {} --  w: {}, b: {}, d: {} (total: {})'.format(\n",
    "            new_batch_index, stats[1], stats[2], stats[3], stats[1] + stats[2] + stats[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
