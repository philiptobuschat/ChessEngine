{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import sys, os\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "sys.path.append(project_root)\n",
    "\n",
    "from Resources.Model import Model_v7, Model_v8\n",
    "from Resources.Game import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nv7: 0 - 10610 \\n\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "v7: 0 - 10610 \n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gamma = 0.98\n",
    "# value_diff_scale = 50\n",
    "\n",
    "# error_hist = []\n",
    "# game_count = 0\n",
    "# draw_count = 0\n",
    "\n",
    "# criterion = nn.MSELoss()\n",
    "# model = Model_v7() # Conv large\n",
    "# model.train()\n",
    "# # model.load_state_dict(torch.load('../Monte Carlo//Model Saves MC v4/model_36510_games'))\n",
    "# white_wins = 0\n",
    "# black_wins = 0\n",
    "# draws = 0\n",
    "\n",
    "# # for each game, save the average difference in value per move. Unpredictable random game should jump a lot.\n",
    "# # Reasoable game should be stable or show slow conversions.\n",
    "# avr_value_jump_hist = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Structure and number of trainable parameters\n",
    "\n",
    "# print(sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
    "# for p in model.parameters():\n",
    "#     if p.requires_grad:\n",
    "#         print(p.shape, p.numel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time for 100 game =  61.40547800064087\n"
     ]
    }
   ],
   "source": [
    "\n",
    "value_diff_scale = 250\n",
    "\n",
    "test_count = 0\n",
    "\n",
    "test_t0 = time.time()\n",
    "\n",
    "# i_limit = 1000\n",
    "while True:\n",
    "    t0 = time.time()\n",
    "\n",
    "    game = Game()\n",
    "    next_root = None\n",
    "    i = 0\n",
    "    boards_white = [];  boards_black = []\n",
    "    mat_white = [];     mat_black = []\n",
    "    value_white = [];   value_black = []\n",
    "\n",
    "    curr_value_jump_tot_white = 0\n",
    "    curr_value_jump_tot_black = 0\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    while not game.is_over():\n",
    "        i += 1\n",
    "        if i > i_limit:\n",
    "            break\n",
    "\n",
    "        current_boards = []; current_labels = []\n",
    "    \n",
    "        moves = game.PossibleMoves()\n",
    "\n",
    "        game_ini = game.copy()\n",
    "        board_batch = [board_to_tensor(game.pieces)]\n",
    "\n",
    "        mate = False\n",
    "\n",
    "        for move in moves:\n",
    "            game.PlayMove(move)\n",
    "            board_batch.append(board_to_tensor(game.pieces))\n",
    "            game.FlipBoard()\n",
    "            if game.is_over():\n",
    "                mate = True\n",
    "                chosen_move = move\n",
    "                game = game_ini.copy()\n",
    "                break\n",
    "            game = game_ini.copy()\n",
    "\n",
    "        if not mate:\n",
    "            board_tensor = torch.stack(board_batch)\n",
    "            values = model(board_tensor)\n",
    "            # if i < 11:\n",
    "            #     scale = value_diff_scale/15\n",
    "            # elif i < 21:\n",
    "            #     scale = value_diff_scale/3\n",
    "            # else:\n",
    "            #     scale = value_diff_scale*3\n",
    "            scale = value_diff_scale\n",
    "            values_diff = [scale*(values[i] - values[0]) for i in range(1, len(values))]\n",
    "            move_prob = torch.softmax(torch.Tensor(values_diff), dim=0).numpy()\n",
    "            # print(move_prob)\n",
    "            chosen_i = np.random.choice(range(len(moves)), p=move_prob)\n",
    "            chosen_move = moves[chosen_i]\n",
    "            \n",
    "        game.PlayMove(chosen_move)\n",
    "\n",
    "        mat_diff = game.MaterialDiff()\n",
    "        value = model(torch.stack([board_to_tensor(game.pieces)])).detach().item()\n",
    "\n",
    "        if i % 2 == 1:\n",
    "            boards_white.append(board_to_tensor(game.pieces))\n",
    "            mat_white.append(mat_diff)\n",
    "            value_white.append(value)\n",
    "            \n",
    "            if i > 1:\n",
    "                curr_value_jump_tot_white += abs(value_white[-1] - value_white[-2])\n",
    "\n",
    "        if i % 2 == 0:\n",
    "            boards_black.append(board_to_tensor(game.pieces))\n",
    "            mat_black.append(mat_diff)\n",
    "            value_black.append(value)\n",
    "\n",
    "            if i > 2:\n",
    "                curr_value_jump_tot_black += abs(value_black[-1] - value_black[-2])\n",
    "\n",
    "        game.FlipBoard()\n",
    "\n",
    "    test_count += 1\n",
    "\n",
    "    if test_count == 100:\n",
    "        print('time for 100 game = ', time.time() - test_t0)\n",
    "        break\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "    avr_value_jump_hist.append( (curr_value_jump_tot_black + curr_value_jump_tot_white) / (i-2) )\n",
    "\n",
    "    if True: #i <= i_limit: # game actually ended\n",
    "        winner = game.get_winner()\n",
    "        if winner == 'draw':\n",
    "            draws += 1;         reward_white = 0;   reward_black = 0\n",
    "        if winner == 'white':\n",
    "            white_wins += 1;    reward_white = 1;   reward_black = -1\n",
    "        if winner == 'black':\n",
    "            black_wins += 1;    reward_white = -1;  reward_black = 1\n",
    "\n",
    "    # else: # game terminated because too long\n",
    "    #     matdiff = game.MaterialDiff()\n",
    "    #     if matdiff > 4:\n",
    "    #         if game.turn == 'white':\n",
    "    #             winner = 'white'; reward_white = 0.5;   reward_black = -0.5;    white_wins += 0.5\n",
    "    #         if game.turn == 'black':\n",
    "    #             winner = 'black'; reward_white = -0.5;  reward_black = 0.5;     black_wins = 0.5\n",
    "    #     elif matdiff < -4:\n",
    "    #         if game.turn == 'white':\n",
    "    #             winner = 'black'; reward_white = -0.5;  reward_black = 0.5;     black_wins += 0.5\n",
    "    #         if game.turn == 'black':\n",
    "    #             winner = 'white'; reward_white = 0.5;   reward_black = -0.5;    white_wins = 0.5\n",
    "    #     else:\n",
    "    #         winner = 'draw'; draws += 1; reward_white = 0; reward_black = 0\n",
    "\n",
    "    # if i > i_limit:\n",
    "    #     print('game termianted, mat diff = ', matdiff)\n",
    "\n",
    "    game_time = time.time() - t0\n",
    "    # print('game_time: ', game_time, 'i max: ', i)\n",
    "\n",
    "    labels_white = [reward_white * gamma**(len(boards_white) - 1 - i) for i in range(len(boards_white))]\n",
    "    labels_black = [reward_black * gamma**(len(boards_black) - 1 - i) for i in range(len(boards_black))]\n",
    "\n",
    "    inputs = boards_white + boards_black\n",
    "    labels = labels_white + labels_black\n",
    "\n",
    "    inputs_tens = torch.stack(inputs)\n",
    "    labels_tens = torch.Tensor(labels)   \n",
    "\n",
    "    if winner != 'draw':\n",
    "        # newest training error\n",
    "        out = model(inputs_tens)\n",
    "        out = out.view(out.shape[0])\n",
    "        loss = criterion(out, labels_tens)\n",
    "        error_hist.append(loss.item())\n",
    "    else:\n",
    "        draw_count += 1\n",
    "        continue\n",
    "\n",
    "    if game_count % 10 == 0:\n",
    "        print(' -- {} -- winner: {}, i: {}   '.format(game_count, winner, i), 'wins: w = {}, b = {}, d = {}'.format(white_wins, black_wins, draws))\n",
    "\n",
    "    if game_count % 50 == 1:# or True:\n",
    "        plt.figure(figsize=(6, 3))\n",
    "        plt.plot(mat_white, label='mat white')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        plt.figure(figsize=(6, 3))\n",
    "        plt.plot(value_white, label='value white')\n",
    "        plt.plot(value_black, label='value black')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        plt.figure(figsize=(6, 3))\n",
    "        plt.plot([np.mean(avr_value_jump_hist[i:i+400]) for i in range(len(avr_value_jump_hist) - 400)], label='average value jumps, rolling mean(400)')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    torch.save(inputs_tens, '/Users/Philip/Desktop/Projects/RL Chess/MCTS/Game Saves v7/inputs_{}'.format(game_count))\n",
    "    torch.save(labels_tens, '/Users/Philip/Desktop/Projects/RL Chess/MCTS/Game Saves v7/labels_{}'.format(game_count))\n",
    "\n",
    "    t1 = time.time()\n",
    "\n",
    "    if game_count > 5:\n",
    "        # sample some of previous game for replay. More recent -> more likely\n",
    "        decay_rate = 0.003\n",
    "        prob =  np.exp(-decay_rate * np.arange(game_count)) \n",
    "        prob = prob /sum(prob)\n",
    "        num_samples = 3\n",
    "        samples = np.random.choice(np.arange(game_count, 0, -1), size=num_samples, p=prob)\n",
    "\n",
    "        for indices in samples:\n",
    "            inputs_load = torch.load('/Users/Philip/Desktop/Projects/RL Chess/MCTS/Game Saves v7/inputs_{}'.format(indices))\n",
    "            inputs_tens = torch.cat((inputs_load, inputs_tens))\n",
    "            labels_tens = torch.cat((torch.load('/Users/Philip/Desktop/Projects/RL Chess/MCTS/Game Saves v7/labels_{}'.format(indices)), labels_tens))\n",
    "\n",
    "    len_boards = len(inputs_tens)\n",
    "    for c in range(len_boards):\n",
    "        tens = inputs_tens[c]\n",
    "        # if no pawns are on the board: add all other 3 rotated versions of the board to the current data set\n",
    "        if torch.sum(inputs_tens[c][0]) + torch.sum(inputs_tens[c][6]) == 0:\n",
    "            board_new = tensor_to_board(tens)\n",
    "            for _ in range(3):\n",
    "                board_new = rotate_board(board_new, 1)\n",
    "                tens_new = torch.stack([board_to_tensor(board_new)])\n",
    "                inputs_tens = torch.cat((inputs_tens, tens_new), 0)\n",
    "                labels_tens = torch.cat((labels_tens, torch.stack([labels_tens[c]])), 0)\n",
    "    \n",
    "    model.train()\n",
    "    # learning_rate = 5e-4 * 500 / (500 + game_count) # reducing learning rate, 1/n one possible options\n",
    "    learning_rate = 5e-5\n",
    "    # weight_decay = 1e-2 # regularization to avoid overfitting\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    random_order = [i for i in range(len(inputs_tens))]\n",
    "    np.random.shuffle(random_order)\n",
    "    for c in random_order:\n",
    "\n",
    "        inp = torch.stack([inputs_tens[c], mirror_board_tensor(inputs_tens[c])])\n",
    "        label = torch.stack([labels_tens[c], labels_tens[c]])\n",
    "\n",
    "        out = model(inp)\n",
    "        out = out.view(out.shape[0])\n",
    "\n",
    "        loss = criterion(out, label)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # torch.nn.utils.clip_grad_norm_(model.parameters(), max_gradient_norm)\n",
    "        optimizer.step()\n",
    "\n",
    "    # print('game time: {} -- training time: {},  '.format(game_time, time.time() - t1))\n",
    "    # print('sum of losses: ', sum(err_curr))\n",
    "\n",
    "    # error_hist.append(sum(err_curr))\n",
    "    \n",
    "    torch.save(error_hist, './error_hist MC v7')\n",
    "\n",
    "    if game_count % 100  == 1:\n",
    "        # plt.plot(error_hist)\n",
    "        # plt.title('training errors')\n",
    "        # plt.show()\n",
    "        interval = 400\n",
    "        plt.figure(figsize=(6, 3))\n",
    "        plt.plot([np.mean(error_hist[i:i+interval]) for i in range(len(error_hist) - interval)], label='error hist, rolling mean '+str(interval))\n",
    "        plt.show()\n",
    "\n",
    "    if game_count % 100 == 9:    \n",
    "        torch.save(model.state_dict(), './Model Saves MC v7/model_{}_games'.format(game_count+1))\n",
    "\n",
    "    game_count += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95813\n",
      "2188757\n"
     ]
    }
   ],
   "source": [
    "model = Model_v7()\n",
    "print(sum(i.numel() for i in model.parameters()))\n",
    "\n",
    "model = Model_v8()\n",
    "print(sum(i.numel() for i in model.parameters()))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
