{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import sys, os\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "sys.path.append(project_root)\n",
    "\n",
    "from Resources.Model import Model_v28\n",
    "from Resources.Game import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### global parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 0.98\n",
    "\n",
    "def scale(i):\n",
    "    return i**2\n",
    "\n",
    "# games saved in batches to reduce i/o stream\n",
    "# each batch is a input file and a label file containing [batch_size] individual games\n",
    "batch_target = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### local counters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "white_wins = 0\n",
    "black_wins = 0\n",
    "draws = 0\n",
    "\n",
    "batch_count = 0         # number of batches locally done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local batches: 399 --  w: 38823, b: 38193, d: 114474\n",
      " -- global batches = 788 --  w: 76808, b: 74955, d: 225360 (total: 377123)\n",
      "local batches: 400 --  w: 38929, b: 38290, d: 114767\n",
      "local batches: 401 --  w: 39003, b: 38379, d: 115100\n",
      "local batches: 402 --  w: 39103, b: 38466, d: 115410\n",
      "local batches: 403 --  w: 39202, b: 38561, d: 115713\n",
      "local batches: 404 --  w: 39295, b: 38638, d: 116040\n",
      " -- global batches = 803 --  w: 78258, b: 76282, d: 230031 (total: 384571)\n",
      "local batches: 405 --  w: 39395, b: 38739, d: 116336\n",
      "local batches: 406 --  w: 39488, b: 38834, d: 116645\n",
      "local batches: 407 --  w: 39576, b: 38938, d: 116950\n",
      "local batches: 408 --  w: 39696, b: 39036, d: 117229\n",
      "local batches: 409 --  w: 39794, b: 39144, d: 117520\n",
      " -- global batches = 818 --  w: 79751, b: 77736, d: 234539 (total: 392026)\n",
      "local batches: 410 --  w: 39882, b: 39245, d: 117828\n",
      "local batches: 411 --  w: 39978, b: 39326, d: 118148\n",
      "local batches: 412 --  w: 40080, b: 39430, d: 118439\n",
      "local batches: 413 --  w: 40166, b: 39537, d: 118744\n",
      "local batches: 414 --  w: 40276, b: 39638, d: 119031\n",
      " -- global batches = 833 --  w: 81227, b: 79194, d: 239066 (total: 399487)\n",
      "local batches: 415 --  w: 40368, b: 39728, d: 119347\n",
      "local batches: 416 --  w: 40459, b: 39796, d: 119686\n",
      "local batches: 417 --  w: 40550, b: 39883, d: 120006\n",
      "local batches: 418 --  w: 40646, b: 39968, d: 120323\n",
      "local batches: 419 --  w: 40733, b: 40052, d: 120650\n",
      " -- global batches = 848 --  w: 82651, b: 80543, d: 243762 (total: 406956)\n",
      "local batches: 420 --  w: 40826, b: 40146, d: 120961\n",
      "local batches: 421 --  w: 40926, b: 40245, d: 121260\n",
      "local batches: 422 --  w: 41010, b: 40339, d: 121580\n",
      "local batches: 423 --  w: 41101, b: 40432, d: 121895\n",
      "local batches: 424 --  w: 41189, b: 40512, d: 122226\n",
      " -- global batches = 863 --  w: 84079, b: 81924, d: 248427 (total: 414430)\n",
      "local batches: 425 --  w: 41297, b: 40594, d: 122535\n",
      "local batches: 426 --  w: 41394, b: 40686, d: 122845\n",
      "local batches: 427 --  w: 41512, b: 40759, d: 123153\n",
      "local batches: 428 --  w: 41623, b: 40860, d: 123440\n",
      "local batches: 429 --  w: 41710, b: 40954, d: 123758\n",
      " -- global batches = 878 --  w: 85521, b: 83282, d: 253112 (total: 421915)\n",
      "local batches: 430 --  w: 41802, b: 41058, d: 124061\n",
      "local batches: 431 --  w: 41909, b: 41152, d: 124359\n",
      "local batches: 432 --  w: 41999, b: 41251, d: 124670\n",
      "local batches: 433 --  w: 42094, b: 41350, d: 124976\n",
      "local batches: 434 --  w: 42173, b: 41447, d: 125300\n",
      " -- global batches = 893 --  w: 86919, b: 84700, d: 257790 (total: 429409)\n",
      "local batches: 435 --  w: 42282, b: 41551, d: 125587\n",
      "local batches: 436 --  w: 42386, b: 41637, d: 125897\n",
      "local batches: 437 --  w: 42476, b: 41742, d: 126202\n",
      "local batches: 438 --  w: 42580, b: 41844, d: 126496\n",
      "local batches: 439 --  w: 42666, b: 41926, d: 126828\n",
      " -- global batches = 908 --  w: 88380, b: 86092, d: 262437 (total: 436909)\n",
      "local batches: 440 --  w: 42758, b: 42019, d: 127143\n",
      "local batches: 441 --  w: 42854, b: 42116, d: 127450\n",
      "local batches: 442 --  w: 42965, b: 42203, d: 127753\n",
      "local batches: 443 --  w: 43065, b: 42306, d: 128050\n",
      "local batches: 444 --  w: 43166, b: 42401, d: 128355\n",
      " -- global batches = 923 --  w: 89850, b: 87526, d: 267038 (total: 444414)\n",
      "local batches: 445 --  w: 43276, b: 42478, d: 128669\n",
      "local batches: 446 --  w: 43384, b: 42566, d: 128974\n",
      "local batches: 447 --  w: 43478, b: 42660, d: 129287\n",
      "local batches: 448 --  w: 43561, b: 42756, d: 129609\n",
      "local batches: 449 --  w: 43653, b: 42844, d: 129930\n",
      " -- global batches = 938 --  w: 91251, b: 88921, d: 271757 (total: 451929)\n",
      "local batches: 450 --  w: 43744, b: 42934, d: 130250\n",
      "local batches: 451 --  w: 43835, b: 43018, d: 130576\n",
      "local batches: 452 --  w: 43916, b: 43116, d: 130898\n",
      "local batches: 453 --  w: 44031, b: 43204, d: 131197\n",
      "local batches: 454 --  w: 44134, b: 43307, d: 131493\n",
      " -- global batches = 953 --  w: 92707, b: 90356, d: 276384 (total: 459447)\n",
      "local batches: 455 --  w: 44242, b: 43409, d: 131784\n",
      "local batches: 456 --  w: 44332, b: 43507, d: 132097\n",
      "local batches: 457 --  w: 44435, b: 43611, d: 132392\n",
      "local batches: 458 --  w: 44526, b: 43715, d: 132699\n",
      "local batches: 459 --  w: 44618, b: 43807, d: 133017\n",
      " -- global batches = 967 --  w: 93998, b: 91737, d: 280734 (total: 466469)\n",
      "local batches: 460 --  w: 44723, b: 43895, d: 133326\n",
      "local batches: 461 --  w: 44809, b: 43994, d: 133643\n",
      "local batches: 462 --  w: 44906, b: 44075, d: 133967\n",
      "local batches: 463 --  w: 45002, b: 44159, d: 134289\n",
      "local batches: 464 --  w: 45102, b: 44249, d: 134601\n",
      " -- global batches = 982 --  w: 95366, b: 93160, d: 285473 (total: 473999)\n",
      "local batches: 465 --  w: 45193, b: 44352, d: 134909\n",
      "local batches: 466 --  w: 45281, b: 44443, d: 135232\n",
      "local batches: 467 --  w: 45389, b: 44534, d: 135536\n",
      "local batches: 468 --  w: 45477, b: 44627, d: 135858\n",
      "local batches: 469 --  w: 45568, b: 44724, d: 136173\n",
      " -- global batches = 997 --  w: 96772, b: 94575, d: 290190 (total: 481537)\n",
      "local batches: 470 --  w: 45662, b: 44822, d: 136484\n",
      "local batches: 471 --  w: 45763, b: 44909, d: 136799\n",
      "local batches: 472 --  w: 45851, b: 45016, d: 137107\n",
      "local batches: 473 --  w: 45953, b: 45103, d: 137421\n",
      "local batches: 474 --  w: 46070, b: 45181, d: 137729\n",
      " -- global batches = 1012 --  w: 98209, b: 95948, d: 294925 (total: 489082)\n",
      "local batches: 475 --  w: 46171, b: 45267, d: 138045\n",
      "local batches: 476 --  w: 46293, b: 45356, d: 138337\n",
      "local batches: 477 --  w: 46378, b: 45460, d: 138651\n",
      "local batches: 478 --  w: 46474, b: 45545, d: 138973\n",
      "local batches: 479 --  w: 46578, b: 45633, d: 139285\n",
      " -- global batches = 1027 --  w: 99693, b: 97370, d: 299565 (total: 496628)\n",
      "local batches: 480 --  w: 46670, b: 45740, d: 139590\n",
      "local batches: 481 --  w: 46781, b: 45836, d: 139887\n",
      "local batches: 482 --  w: 46886, b: 45934, d: 140188\n",
      "local batches: 483 --  w: 46992, b: 46034, d: 140486\n",
      "local batches: 484 --  w: 47069, b: 46128, d: 140819\n",
      " -- global batches = 1042 --  w: 101146, b: 98816, d: 304226 (total: 504188)\n",
      "local batches: 485 --  w: 47153, b: 46227, d: 141140\n",
      "local batches: 486 --  w: 47269, b: 46330, d: 141425\n",
      "local batches: 487 --  w: 47338, b: 46424, d: 141766\n",
      "local batches: 488 --  w: 47447, b: 46530, d: 142055\n",
      "local batches: 489 --  w: 47556, b: 46613, d: 142367\n",
      " -- global batches = 1057 --  w: 102532, b: 100264, d: 308952 (total: 511748)\n",
      "local batches: 490 --  w: 47649, b: 46690, d: 142701\n",
      "local batches: 491 --  w: 47747, b: 46778, d: 143019\n",
      "local batches: 492 --  w: 47843, b: 46873, d: 143332\n",
      "local batches: 493 --  w: 47932, b: 46967, d: 143653\n",
      "local batches: 494 --  w: 48033, b: 47054, d: 143970\n",
      " -- global batches = 1072 --  w: 103959, b: 101644, d: 313706 (total: 519309)\n",
      "local batches: 495 --  w: 48115, b: 47153, d: 144294\n",
      "local batches: 496 --  w: 48199, b: 47258, d: 144610\n",
      "local batches: 497 --  w: 48291, b: 47352, d: 144929\n",
      "local batches: 498 --  w: 48384, b: 47451, d: 145242\n",
      "local batches: 499 --  w: 48486, b: 47543, d: 145553\n",
      " -- global batches = 1087 --  w: 105308, b: 103022, d: 318554 (total: 526884)\n",
      "local batches: 500 --  w: 48580, b: 47646, d: 145861\n",
      "local batches: 501 --  w: 48674, b: 47743, d: 146175\n",
      "local batches: 502 --  w: 48770, b: 47831, d: 146496\n",
      "local batches: 503 --  w: 48862, b: 47936, d: 146804\n",
      "local batches: 504 --  w: 48954, b: 48035, d: 147118\n",
      " -- global batches = 1102 --  w: 106715, b: 104491, d: 323253 (total: 534459)\n",
      "local batches: 505 --  w: 49035, b: 48131, d: 147447\n",
      "local batches: 506 --  w: 49125, b: 48214, d: 147780\n",
      "local batches: 507 --  w: 49217, b: 48288, d: 148120\n",
      "local batches: 508 --  w: 49297, b: 48371, d: 148463\n",
      "local batches: 509 --  w: 49393, b: 48452, d: 148792\n",
      " -- global batches = 1117 --  w: 108028, b: 105828, d: 328193 (total: 542049)\n",
      "local batches: 510 --  w: 49494, b: 48534, d: 149115\n",
      "local batches: 511 --  w: 49595, b: 48618, d: 149437\n",
      "local batches: 512 --  w: 49690, b: 48709, d: 149758\n",
      "local batches: 513 --  w: 49779, b: 48791, d: 150094\n",
      "local batches: 514 --  w: 49873, b: 48889, d: 150409\n",
      " -- global batches = 1132 --  w: 109449, b: 107123, d: 333077 (total: 549649)\n",
      "local batches: 515 --  w: 49963, b: 48971, d: 150744\n",
      "local batches: 516 --  w: 50043, b: 49071, d: 151071\n",
      "local batches: 517 --  w: 50140, b: 49153, d: 151399\n",
      "local batches: 518 --  w: 50230, b: 49259, d: 151711\n",
      "local batches: 519 --  w: 50313, b: 49359, d: 152036\n",
      " -- global batches = 1147 --  w: 110778, b: 108517, d: 337964 (total: 557259)\n",
      "local batches: 520 --  w: 50427, b: 49440, d: 152349\n",
      "local batches: 521 --  w: 50524, b: 49506, d: 152694\n",
      "local batches: 522 --  w: 50621, b: 49595, d: 153016\n",
      "local batches: 523 --  w: 50697, b: 49679, d: 153364\n",
      "local batches: 524 --  w: 50793, b: 49760, d: 153695\n",
      " -- global batches = 1162 --  w: 112112, b: 109813, d: 342954 (total: 564879)\n",
      "local batches: 525 --  w: 50883, b: 49853, d: 154021\n",
      "local batches: 526 --  w: 50980, b: 49938, d: 154348\n",
      "local batches: 527 --  w: 51079, b: 50040, d: 154656\n",
      "local batches: 528 --  w: 51172, b: 50137, d: 154975\n",
      "local batches: 529 --  w: 51267, b: 50220, d: 155306\n",
      " -- global batches = 1177 --  w: 113449, b: 111183, d: 347881 (total: 572513)\n",
      "local batches: 530 --  w: 51353, b: 50315, d: 155634\n",
      "local batches: 531 --  w: 51453, b: 50406, d: 155952\n",
      "local batches: 532 --  w: 51543, b: 50505, d: 156272\n",
      "local batches: 533 --  w: 51637, b: 50605, d: 156588\n",
      "local batches: 534 --  w: 51717, b: 50692, d: 156931\n",
      " -- global batches = 1191 --  w: 114699, b: 112456, d: 352489 (total: 579644)\n",
      "local batches: 535 --  w: 51807, b: 50785, d: 157258\n",
      "local batches: 536 --  w: 51899, b: 50872, d: 157589\n",
      "local batches: 537 --  w: 51986, b: 50973, d: 157911\n",
      "local batches: 538 --  w: 52066, b: 51070, d: 158244\n",
      "local batches: 539 --  w: 52158, b: 51156, d: 158576\n",
      " -- global batches = 1206 --  w: 116062, b: 113762, d: 357470 (total: 587294)\n",
      "local batches: 540 --  w: 52243, b: 51244, d: 158914\n",
      "local batches: 541 --  w: 52324, b: 51337, d: 159251\n",
      "local batches: 542 --  w: 52403, b: 51431, d: 159589\n",
      "local batches: 543 --  w: 52482, b: 51552, d: 159900\n",
      "local batches: 544 --  w: 52577, b: 51634, d: 160234\n",
      " -- global batches = 1221 --  w: 117348, b: 115096, d: 362514 (total: 594958)\n",
      "local batches: 545 --  w: 52676, b: 51709, d: 160571\n",
      "local batches: 546 --  w: 52752, b: 51809, d: 160907\n",
      "local batches: 547 --  w: 52850, b: 51900, d: 161230\n",
      "local batches: 548 --  w: 52951, b: 51987, d: 161554\n",
      "local batches: 549 --  w: 53054, b: 52076, d: 161874\n",
      " -- global batches = 1236 --  w: 118674, b: 116432, d: 367527 (total: 602633)\n",
      "local batches: 550 --  w: 53152, b: 52163, d: 162201\n",
      "local batches: 551 --  w: 53243, b: 52247, d: 162538\n",
      "local batches: 552 --  w: 53347, b: 52345, d: 162848\n",
      "local batches: 553 --  w: 53444, b: 52456, d: 163153\n",
      "local batches: 554 --  w: 53537, b: 52551, d: 163478\n",
      " -- global batches = 1251 --  w: 120053, b: 117815, d: 372451 (total: 610319)\n",
      "local batches: 555 --  w: 53632, b: 52622, d: 163825\n",
      "local batches: 556 --  w: 53745, b: 52727, d: 164120\n",
      "local batches: 557 --  w: 53830, b: 52822, d: 164453\n",
      "local batches: 558 --  w: 53924, b: 52934, d: 164760\n",
      "local batches: 559 --  w: 54012, b: 53019, d: 165100\n",
      " -- global batches = 1265 --  w: 121384, b: 119132, d: 376985 (total: 617501)\n",
      "local batches: 560 --  w: 54093, b: 53100, d: 165451\n",
      "local batches: 561 --  w: 54195, b: 53181, d: 165781\n",
      "local batches: 562 --  w: 54280, b: 53265, d: 166125\n",
      "local batches: 563 --  w: 54361, b: 53360, d: 166462\n",
      "local batches: 564 --  w: 54466, b: 53452, d: 166779\n",
      " -- global batches = 1280 --  w: 122743, b: 120456, d: 381999 (total: 625198)\n",
      "local batches: 565 --  w: 54567, b: 53537, d: 167107\n",
      "local batches: 566 --  w: 54653, b: 53637, d: 167435\n",
      "local batches: 567 --  w: 54754, b: 53716, d: 167769\n",
      "local batches: 568 --  w: 54847, b: 53795, d: 168111\n",
      "local batches: 569 --  w: 54943, b: 53872, d: 168452\n",
      " -- global batches = 1296 --  w: 124299, b: 121864, d: 387259 (total: 633422)\n",
      "local batches: 570 --  w: 55040, b: 53949, d: 168792\n",
      "local batches: 571 --  w: 55135, b: 54034, d: 169126\n",
      "local batches: 572 --  w: 55245, b: 54103, d: 169461\n",
      "local batches: 573 --  w: 55337, b: 54204, d: 169783\n",
      "local batches: 574 --  w: 55419, b: 54296, d: 170124\n",
      " -- global batches = 1311 --  w: 125679, b: 123172, d: 392285 (total: 641136)\n",
      "local batches: 575 --  w: 55510, b: 54393, d: 170451\n",
      "local batches: 576 --  w: 55596, b: 54493, d: 170780\n",
      "local batches: 577 --  w: 55683, b: 54585, d: 171116\n",
      "local batches: 578 --  w: 55778, b: 54673, d: 171448\n",
      "local batches: 579 --  w: 55866, b: 54772, d: 171776\n",
      " -- global batches = 1326 --  w: 127052, b: 124592, d: 397217 (total: 648861)\n",
      "local batches: 580 --  w: 55956, b: 54874, d: 172099\n",
      "local batches: 581 --  w: 56053, b: 54949, d: 172442\n",
      "local batches: 582 --  w: 56150, b: 55052, d: 172757\n",
      "local batches: 583 --  w: 56244, b: 55144, d: 173086\n",
      "local batches: 584 --  w: 56331, b: 55238, d: 173421\n",
      " -- global batches = 1341 --  w: 128431, b: 125980, d: 402178 (total: 656589)\n",
      "local batches: 585 --  w: 56408, b: 55333, d: 173765\n",
      "local batches: 586 --  w: 56494, b: 55422, d: 174106\n",
      "local batches: 587 --  w: 56589, b: 55533, d: 174416\n",
      "local batches: 588 --  w: 56681, b: 55620, d: 174753\n",
      "local batches: 589 --  w: 56785, b: 55714, d: 175071\n",
      " -- global batches = 1355 --  w: 129688, b: 127296, d: 406829 (total: 663813)\n",
      "local batches: 590 --  w: 56886, b: 55810, d: 175390\n",
      "local batches: 591 --  w: 56979, b: 55907, d: 175716\n",
      "local batches: 592 --  w: 57083, b: 55995, d: 176040\n",
      "local batches: 593 --  w: 57193, b: 56091, d: 176350\n",
      "local batches: 594 --  w: 57292, b: 56172, d: 176686\n",
      " -- global batches = 1369 --  w: 131024, b: 128618, d: 411395 (total: 671037)\n",
      "local batches: 595 --  w: 57395, b: 56254, d: 177017\n",
      "local batches: 596 --  w: 57487, b: 56344, d: 177351\n",
      "local batches: 597 --  w: 57582, b: 56429, d: 177688\n",
      "local batches: 598 --  w: 57692, b: 56515, d: 178009\n",
      "local batches: 599 --  w: 57789, b: 56618, d: 178326\n",
      " -- global batches = 1384 --  w: 132500, b: 130003, d: 416281 (total: 678784)\n",
      "local batches: 600 --  w: 57885, b: 56721, d: 178644\n",
      "local batches: 601 --  w: 57951, b: 56833, d: 178983\n",
      "local batches: 602 --  w: 58041, b: 56922, d: 179321\n",
      "local batches: 603 --  w: 58128, b: 57011, d: 179662\n",
      "local batches: 604 --  w: 58217, b: 57103, d: 179998\n",
      " -- global batches = 1399 --  w: 133880, b: 131437, d: 421222 (total: 686539)\n",
      "local batches: 605 --  w: 58308, b: 57205, d: 180322\n",
      "local batches: 606 --  w: 58395, b: 57292, d: 180665\n",
      "local batches: 607 --  w: 58482, b: 57373, d: 181014\n",
      "local batches: 608 --  w: 58584, b: 57473, d: 181329\n",
      "local batches: 609 --  w: 58666, b: 57575, d: 181662\n",
      " -- global batches = 1414 --  w: 135298, b: 132849, d: 426147 (total: 694294)\n",
      "local batches: 610 --  w: 58749, b: 57662, d: 182009\n",
      "local batches: 611 --  w: 58837, b: 57760, d: 182340\n",
      "local batches: 612 --  w: 58936, b: 57838, d: 182681\n",
      "local batches: 613 --  w: 59028, b: 57926, d: 183019\n",
      "local batches: 614 --  w: 59112, b: 58014, d: 183365\n",
      " -- global batches = 1429 --  w: 136665, b: 134168, d: 431225 (total: 702058)\n",
      "local batches: 615 --  w: 59197, b: 58080, d: 183732\n",
      "local batches: 616 --  w: 59281, b: 58160, d: 184086\n",
      "local batches: 617 --  w: 59381, b: 58255, d: 184409\n",
      "local batches: 618 --  w: 59471, b: 58349, d: 184743\n",
      "local batches: 619 --  w: 59555, b: 58444, d: 185082\n",
      " -- global batches = 1444 --  w: 138033, b: 135482, d: 436313 (total: 709828)\n",
      "local batches: 620 --  w: 59632, b: 58545, d: 185423\n",
      "local batches: 621 --  w: 59707, b: 58652, d: 185760\n",
      "local batches: 622 --  w: 59816, b: 58741, d: 186081\n",
      "local batches: 623 --  w: 59916, b: 58803, d: 186438\n",
      "local batches: 624 --  w: 60012, b: 58888, d: 186776\n",
      " -- global batches = 1459 --  w: 139423, b: 136788, d: 441401 (total: 717612)\n",
      "local batches: 625 --  w: 60098, b: 58979, d: 187118\n",
      "local batches: 626 --  w: 60181, b: 59082, d: 187451\n",
      "local batches: 627 --  w: 60266, b: 59149, d: 187818\n",
      "local batches: 628 --  w: 60342, b: 59239, d: 188171\n",
      "local batches: 629 --  w: 60440, b: 59330, d: 188502\n",
      " -- global batches = 1474 --  w: 140734, b: 138148, d: 446518 (total: 725400)\n",
      "local batches: 630 --  w: 60533, b: 59422, d: 188837\n",
      "local batches: 631 --  w: 60633, b: 59501, d: 189178\n",
      "local batches: 632 --  w: 60736, b: 59599, d: 189497\n",
      "local batches: 633 --  w: 60827, b: 59685, d: 189840\n",
      "local batches: 634 --  w: 60910, b: 59777, d: 190185\n",
      " -- global batches = 1489 --  w: 142119, b: 139536, d: 451545 (total: 733200)\n",
      "local batches: 635 --  w: 61024, b: 59866, d: 190502\n",
      "local batches: 636 --  w: 61128, b: 59954, d: 190830\n",
      "local batches: 637 --  w: 61214, b: 60045, d: 191173\n",
      "local batches: 638 --  w: 61302, b: 60116, d: 191534\n",
      "local batches: 639 --  w: 61393, b: 60204, d: 191875\n",
      " -- global batches = 1504 --  w: 143574, b: 140823, d: 456603 (total: 741000)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/Philip/Desktop/GitHub/ChessEngine/Train Value Function/Monte Carlo/ValueTrain_MC_v28_ParBatched_1.ipynb Cell 6\u001b[0m line \u001b[0;36m7\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Philip/Desktop/GitHub/ChessEngine/Train%20Value%20Function/Monte%20Carlo/ValueTrain_MC_v28_ParBatched_1.ipynb#X15sZmlsZQ%3D%3D?line=67'>68</a>\u001b[0m board_batch\u001b[39m.\u001b[39mappend(board_to_tensor(game\u001b[39m.\u001b[39mpieces))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Philip/Desktop/GitHub/ChessEngine/Train%20Value%20Function/Monte%20Carlo/ValueTrain_MC_v28_ParBatched_1.ipynb#X15sZmlsZQ%3D%3D?line=68'>69</a>\u001b[0m game\u001b[39m.\u001b[39mFlipBoard()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/Philip/Desktop/GitHub/ChessEngine/Train%20Value%20Function/Monte%20Carlo/ValueTrain_MC_v28_ParBatched_1.ipynb#X15sZmlsZQ%3D%3D?line=69'>70</a>\u001b[0m \u001b[39mif\u001b[39;00m game\u001b[39m.\u001b[39;49mis_over():\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Philip/Desktop/GitHub/ChessEngine/Train%20Value%20Function/Monte%20Carlo/ValueTrain_MC_v28_ParBatched_1.ipynb#X15sZmlsZQ%3D%3D?line=70'>71</a>\u001b[0m     mate \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Philip/Desktop/GitHub/ChessEngine/Train%20Value%20Function/Monte%20Carlo/ValueTrain_MC_v28_ParBatched_1.ipynb#X15sZmlsZQ%3D%3D?line=71'>72</a>\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/GitHub/ChessEngine/Resources/Game.py:100\u001b[0m, in \u001b[0;36mGame.is_over\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[39mif\u001b[39;00m (tot \u001b[39m==\u001b[39m \u001b[39m22\u001b[39m\u001b[39m+\u001b[39m\u001b[39m2\u001b[39m \u001b[39mand\u001b[39;00m piece_counts[\u001b[39m2\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m) \u001b[39mor\u001b[39;00m (tot \u001b[39m==\u001b[39m \u001b[39m22\u001b[39m\u001b[39m+\u001b[39m\u001b[39m12\u001b[39m \u001b[39mand\u001b[39;00m piece_counts[\u001b[39m12\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[1;32m     98\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m--> 100\u001b[0m moves \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mPossibleMoves()\n\u001b[1;32m    102\u001b[0m \u001b[39m# No moves available -> stalemate or checkmate\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(moves) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m: \n",
      "File \u001b[0;32m~/Desktop/GitHub/ChessEngine/Resources/Game.py:991\u001b[0m, in \u001b[0;36mGame.PossibleMoves\u001b[0;34m(self, any)\u001b[0m\n\u001b[1;32m    988\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpieces[move[\u001b[39m1\u001b[39m]] \u001b[39m=\u001b[39m moved_piece\n\u001b[1;32m    990\u001b[0m \u001b[39m# perform in check test\u001b[39;00m\n\u001b[0;32m--> 991\u001b[0m incheck \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mInCheck_pieces(opp_pawns, opp_knights, opp_bishops, opp_rooks, \n\u001b[1;32m    992\u001b[0m                            opp_queens, king, opp_king)\n\u001b[1;32m    994\u001b[0m \u001b[39m# reset env to state before\u001b[39;00m\n\u001b[1;32m    995\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpieces[move[\u001b[39m0\u001b[39m]] \u001b[39m=\u001b[39m moved_piece\n",
      "File \u001b[0;32m~/Desktop/GitHub/ChessEngine/Resources/Game.py:306\u001b[0m, in \u001b[0;36mGame.InCheck_pieces\u001b[0;34m(self, pawns, knights, bishops, rooks, queens, king, opp_king, pos)\u001b[0m\n\u001b[1;32m    304\u001b[0m check \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    305\u001b[0m \u001b[39mfor\u001b[39;00m dist \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, dist_steps): \u001b[39m# 1:dist-1\u001b[39;00m\n\u001b[0;32m--> 306\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpieces[king[\u001b[39m0\u001b[39m] \u001b[39m+\u001b[39m dist \u001b[39m*\u001b[39m np\u001b[39m.\u001b[39;49msign(rook[\u001b[39m0\u001b[39;49m] \u001b[39m-\u001b[39;49m king[\u001b[39m0\u001b[39;49m]), king[\u001b[39m1\u001b[39m] \u001b[39m+\u001b[39m dist \u001b[39m*\u001b[39m np\u001b[39m.\u001b[39msign(rook[\u001b[39m1\u001b[39m] \u001b[39m-\u001b[39m king[\u001b[39m1\u001b[39m])] \u001b[39m!=\u001b[39m\u001b[39m0\u001b[39m:\n\u001b[1;32m    307\u001b[0m         check \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    308\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# keep generating new batches of data until stopped\n",
    "while True:\n",
    "\n",
    "    batch_white_wins = 0\n",
    "    batch_black_wins = 0\n",
    "    batch_draws = 0\n",
    "\n",
    "    # load newest model\n",
    "    model = Model_v28()\n",
    "    model_saves = os.listdir('../Monte Carlo/Model Saves MC v28')\n",
    "    if len(model_saves) > 0:\n",
    "        newest_model = max(int(i[6:-8]) for i in model_saves)\n",
    "        model.load_state_dict(torch.load('../Monte Carlo/Model Saves MC v28/model_{}_batches'.format(newest_model)))\n",
    "    else:\n",
    "        time.sleep(0.05)\n",
    "\n",
    "    # print('loaded model ', newest_model)\n",
    "\n",
    "    with open('/Users/Philip/Desktop/Projects/RL Chess/MCTS/Game Saves v28/stats', 'rb') as f:\n",
    "        stats = torch.load(f)\n",
    "    stats = stats.int()\n",
    "    global_white_wins   = stats[1]\n",
    "    global_black_wins   = stats[2]\n",
    "    global_draws        = stats[3]\n",
    "\n",
    "    if (global_white_wins + global_black_wins + global_draws) == 0:\n",
    "        percentage_decisive = 0.5\n",
    "    else:\n",
    "        percentage_decisive = ((global_white_wins + global_black_wins) / (global_white_wins + global_black_wins + global_draws)).item()\n",
    "    \n",
    "    batch_size = int(batch_target // percentage_decisive) # so that on average we have [batch_target] decisive games\n",
    "\n",
    "    meta_games = []\n",
    "    meta_boards_white = []; meta_boards_black = []\n",
    "    i = 0\n",
    "\n",
    "    meta_active = []\n",
    "\n",
    "    for game_ind in range(batch_size):\n",
    "        meta_games.append( Game() )\n",
    "        meta_boards_white.append([]); meta_boards_black.append([])\n",
    "        meta_active.append(True)\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    while True in meta_active:\n",
    "\n",
    "        i += 1\n",
    "        full_board_batch = []\n",
    "        meta_board_batch_sizes = [] # save batch sizes to split model output afterwards\n",
    "        meta_moves = []\n",
    "\n",
    "        # go through games, collect positions for value evaluations\n",
    "        for g, game in enumerate(meta_games):\n",
    "\n",
    "            if not meta_active[g]:\n",
    "                meta_board_batch_sizes.append(0)\n",
    "                meta_moves.append([])\n",
    "                continue\n",
    "\n",
    "            meta_moves.append(game.PossibleMoves())\n",
    "            game_ini = game.copy()\n",
    "            board_batch = [board_to_tensor(game.pieces)]\n",
    "            mate = False\n",
    "\n",
    "            for move in meta_moves[-1]:\n",
    "                game.PlayMove(move)\n",
    "                board_batch.append(board_to_tensor(game.pieces))\n",
    "                game.FlipBoard()\n",
    "                if game.is_over():\n",
    "                    mate = True\n",
    "                    break\n",
    "                game = game_ini.copy()\n",
    "\n",
    "            meta_games[g] = game.copy()\n",
    "\n",
    "            if mate:\n",
    "                meta_active[g] = False\n",
    "                meta_board_batch_sizes.append(0)\n",
    "                game.FlipBoard()\n",
    "                if i % 2 == 1:\n",
    "                    meta_boards_white[g].append(board_to_bool_tensor(game.pieces))\n",
    "                if i % 2 == 0:\n",
    "                    meta_boards_black[g].append(board_to_bool_tensor(game.pieces))\n",
    "\n",
    "            if not mate:\n",
    "                full_board_batch = full_board_batch + board_batch\n",
    "                meta_board_batch_sizes.append(len(board_batch))\n",
    "\n",
    "        if len(full_board_batch) == 0:\n",
    "            break\n",
    "\n",
    "        # get values of all positions\n",
    "        full_board_batch = torch.stack(full_board_batch)\n",
    "        out = model(full_board_batch).detach()\n",
    "        meta_values = torch.split(out, meta_board_batch_sizes)\n",
    "\n",
    "        # make moves for all games\n",
    "        for g, game in enumerate(meta_games):\n",
    "\n",
    "            if not meta_active[g]:\n",
    "                continue\n",
    "            values = meta_values[g]\n",
    "            values_diff = [scale(i)*(values[j] - values[0]) for j in range(1, len(values))]\n",
    "            move_prob = torch.softmax(torch.Tensor(values_diff), dim=0).numpy()\n",
    "            chosen_i = np.random.choice(range(len(meta_moves[g])), p=move_prob)\n",
    "            chosen_move = meta_moves[g][chosen_i]\n",
    "            game.PlayMove(chosen_move)\n",
    "            if i % 2 == 1:\n",
    "                meta_boards_white[g].append(board_to_bool_tensor(game.pieces))\n",
    "            if i % 2 == 0:\n",
    "                meta_boards_black[g].append(board_to_bool_tensor(game.pieces))\n",
    "            game.FlipBoard()\n",
    "\n",
    "    meta_inputs = []\n",
    "    meta_labels = []\n",
    "\n",
    "    for g, game in enumerate(meta_games):\n",
    "        \n",
    "        winner = game.get_winner()\n",
    "        if winner == 'draw':\n",
    "            draws += 1; batch_draws += 1\n",
    "            continue\n",
    "            reward_white = 0;   reward_black = 0\n",
    "\n",
    "        elif winner == 'white':\n",
    "            white_wins += 1; batch_white_wins += 1\n",
    "            reward_white = 1;   reward_black = -1\n",
    "\n",
    "        elif winner == 'black':\n",
    "            black_wins += 1; batch_black_wins += 1\n",
    "            reward_white = -1;  reward_black = 1\n",
    "\n",
    "        labels_white = [reward_white * gamma**(len(meta_boards_white[g]) - 1 - i) for i in range(len(meta_boards_white[g]))]\n",
    "        labels_black = [reward_black * gamma**(len(meta_boards_black[g]) - 1 - i) for i in range(len(meta_boards_black[g]))]\n",
    "\n",
    "        meta_inputs = meta_inputs + meta_boards_white[g] + meta_boards_black[g]\n",
    "        meta_labels = meta_labels + labels_white + labels_black\n",
    "\n",
    "    if batch_white_wins + batch_black_wins == 0:\n",
    "        print('no decisive games in the whole batch -> skip to next batch (batch size too small?)')\n",
    "        continue\n",
    "\n",
    "    inputs_tens = torch.stack(meta_inputs)\n",
    "    labels_tens = torch.Tensor(meta_labels)\n",
    "\n",
    "    with open('/Users/Philip/Desktop/Projects/RL Chess/MCTS/Game Saves v28/stats', 'rb') as f:\n",
    "        stats = torch.load(f)\n",
    "    stats = stats.int()\n",
    "    stats[0] += 1;                  stats[1] += batch_white_wins\n",
    "    stats[2] += batch_black_wins;   stats[3] += batch_draws\n",
    "    torch.save(stats, '/Users/Philip/Desktop/Projects/RL Chess/MCTS/Game Saves v28/stats')\n",
    "\n",
    "    new_batch_index = stats[0]\n",
    "    torch.save(inputs_tens, '/Users/Philip/Desktop/Projects/RL Chess/MCTS/Game Saves v28/inputs_{}'.format(new_batch_index))\n",
    "    torch.save(labels_tens, '/Users/Philip/Desktop/Projects/RL Chess/MCTS/Game Saves v28/labels_{}'.format(new_batch_index))\n",
    "\n",
    "    print('local batches: {} --  w: {}, b: {}, d: {}'.format(batch_count, white_wins, black_wins, draws))\n",
    "\n",
    "    batch_count += 1\n",
    "            \n",
    "    if batch_count % 5 == 0:\n",
    "        print(' -- global batches = {} --  w: {}, b: {}, d: {} (total: {})'.format(\n",
    "            new_batch_index, stats[1], stats[2], stats[3], stats[1] + stats[2] + stats[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
