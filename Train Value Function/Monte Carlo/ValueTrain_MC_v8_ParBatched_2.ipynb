{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import sys, os\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "sys.path.append(project_root)\n",
    "\n",
    "from Resources.Model import Model_v8\n",
    "from Resources.Game import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### global parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 0.98\n",
    "value_diff_scale = 50\n",
    "value_diff_scale_early = 1\n",
    "# games saved in batches to reduce i/o stream\n",
    "# each batch is a input file and a label file containing [batch_size] individual games\n",
    "batch_target = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### local counters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "white_wins = 0\n",
    "black_wins = 0\n",
    "draws = 0\n",
    "\n",
    "batch_count = 0         # number of batches locally done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local batches: 0 --  w: 55, b: 50, d: 145\n",
      "local batches: 1 --  w: 102, b: 97, d: 301\n",
      "local batches: 2 --  w: 157, b: 147, d: 446\n",
      "local batches: 3 --  w: 206, b: 202, d: 592\n",
      "local batches: 4 --  w: 257, b: 254, d: 739\n",
      " -- global batches = 1238 --  w: 61788, b: 62028, d: 186594 (total: 310410)\n",
      "local batches: 5 --  w: 313, b: 319, d: 868\n",
      "local batches: 6 --  w: 365, b: 373, d: 1012\n",
      "local batches: 7 --  w: 425, b: 415, d: 1160\n",
      "local batches: 8 --  w: 468, b: 463, d: 1319\n",
      "local batches: 9 --  w: 519, b: 507, d: 1474\n",
      " -- global batches = 1264 --  w: 63198, b: 63357, d: 190355 (total: 316910)\n",
      "local batches: 10 --  w: 569, b: 562, d: 1619\n",
      "local batches: 11 --  w: 620, b: 612, d: 1768\n",
      "local batches: 12 --  w: 680, b: 665, d: 1905\n",
      "local batches: 13 --  w: 743, b: 720, d: 2037\n",
      "local batches: 14 --  w: 803, b: 766, d: 2180\n",
      " -- global batches = 1289 --  w: 64691, b: 64640, d: 193828 (total: 323159)\n",
      "local batches: 15 --  w: 863, b: 816, d: 2319\n",
      "local batches: 16 --  w: 926, b: 847, d: 2474\n",
      "local batches: 17 --  w: 984, b: 888, d: 2624\n",
      "local batches: 18 --  w: 1037, b: 936, d: 2772\n",
      "local batches: 19 --  w: 1095, b: 988, d: 2911\n",
      " -- global batches = 1313 --  w: 65982, b: 65813, d: 197340 (total: 329135)\n",
      "local batches: 20 --  w: 1141, b: 1034, d: 3068\n",
      "local batches: 21 --  w: 1188, b: 1092, d: 3212\n",
      "local batches: 22 --  w: 1244, b: 1134, d: 3363\n",
      "local batches: 23 --  w: 1295, b: 1178, d: 3517\n",
      "local batches: 24 --  w: 1353, b: 1215, d: 3671\n",
      " -- global batches = 1338 --  w: 67288, b: 66974, d: 201098 (total: 335360)\n",
      "local batches: 25 --  w: 1397, b: 1261, d: 3830\n",
      "local batches: 26 --  w: 1438, b: 1313, d: 3986\n",
      "local batches: 27 --  w: 1485, b: 1356, d: 4145\n",
      "local batches: 28 --  w: 1534, b: 1408, d: 4293\n",
      "local batches: 29 --  w: 1594, b: 1467, d: 4423\n",
      " -- global batches = 1363 --  w: 68560, b: 68131, d: 204894 (total: 341585)\n",
      "local batches: 30 --  w: 1638, b: 1514, d: 4581\n",
      "local batches: 31 --  w: 1684, b: 1561, d: 4737\n",
      "local batches: 32 --  w: 1727, b: 1603, d: 4901\n",
      "local batches: 33 --  w: 1787, b: 1647, d: 5046\n",
      "local batches: 34 --  w: 1837, b: 1693, d: 5199\n",
      " -- global batches = 1388 --  w: 69871, b: 69319, d: 208620 (total: 347810)\n",
      "local batches: 35 --  w: 1897, b: 1752, d: 5329\n",
      "local batches: 36 --  w: 1950, b: 1801, d: 5476\n",
      "local batches: 37 --  w: 2000, b: 1847, d: 5629\n",
      "local batches: 38 --  w: 2059, b: 1896, d: 5770\n",
      "local batches: 39 --  w: 2120, b: 1944, d: 5910\n",
      " -- global batches = 1413 --  w: 71141, b: 70592, d: 212302 (total: 354035)\n",
      "local batches: 40 --  w: 2171, b: 1989, d: 6063\n",
      "local batches: 41 --  w: 2215, b: 2030, d: 6227\n",
      "local batches: 42 --  w: 2262, b: 2084, d: 6375\n",
      "local batches: 43 --  w: 2307, b: 2138, d: 6525\n",
      "local batches: 44 --  w: 2358, b: 2200, d: 6661\n",
      " -- global batches = 1438 --  w: 72420, b: 71834, d: 216006 (total: 360260)\n",
      "local batches: 45 --  w: 2405, b: 2250, d: 6813\n",
      "local batches: 46 --  w: 2463, b: 2296, d: 6958\n",
      "local batches: 47 --  w: 2531, b: 2351, d: 7084\n",
      "local batches: 48 --  w: 2578, b: 2394, d: 7243\n",
      "local batches: 49 --  w: 2635, b: 2445, d: 7384\n",
      " -- global batches = 1463 --  w: 73692, b: 73081, d: 219712 (total: 366485)\n",
      "local batches: 50 --  w: 2680, b: 2507, d: 7526\n",
      "local batches: 51 --  w: 2739, b: 2549, d: 7674\n",
      "local batches: 52 --  w: 2812, b: 2599, d: 7800\n",
      "local batches: 53 --  w: 2866, b: 2655, d: 7939\n",
      "local batches: 54 --  w: 2912, b: 2691, d: 8106\n",
      " -- global batches = 1488 --  w: 75014, b: 74291, d: 223405 (total: 372710)\n",
      "local batches: 55 --  w: 2970, b: 2745, d: 8243\n",
      "local batches: 56 --  w: 3025, b: 2804, d: 8378\n",
      "local batches: 57 --  w: 3082, b: 2860, d: 8514\n",
      "local batches: 58 --  w: 3134, b: 2909, d: 8662\n",
      "local batches: 59 --  w: 3180, b: 2965, d: 8809\n",
      " -- global batches = 1513 --  w: 76361, b: 75607, d: 226967 (total: 378935)\n",
      "local batches: 60 --  w: 3228, b: 3011, d: 8964\n",
      "local batches: 61 --  w: 3284, b: 3077, d: 9091\n",
      "local batches: 62 --  w: 3344, b: 3129, d: 9228\n",
      "local batches: 63 --  w: 3399, b: 3190, d: 9361\n",
      "local batches: 64 --  w: 3457, b: 3237, d: 9505\n",
      " -- global batches = 1538 --  w: 77766, b: 76922, d: 230472 (total: 385160)\n",
      "local batches: 65 --  w: 3506, b: 3295, d: 9646\n",
      "local batches: 66 --  w: 3547, b: 3336, d: 9812\n",
      "local batches: 67 --  w: 3583, b: 3385, d: 9975\n",
      "local batches: 68 --  w: 3633, b: 3448, d: 10110\n",
      "local batches: 69 --  w: 3692, b: 3506, d: 10242\n",
      " -- global batches = 1563 --  w: 79024, b: 78178, d: 234167 (total: 391369)\n",
      "local batches: 70 --  w: 3737, b: 3553, d: 10398\n",
      "local batches: 71 --  w: 3789, b: 3598, d: 10549\n",
      "local batches: 72 --  w: 3833, b: 3653, d: 10698\n",
      "local batches: 73 --  w: 3882, b: 3697, d: 10853\n",
      "local batches: 74 --  w: 3937, b: 3737, d: 11006\n",
      " -- global batches = 1588 --  w: 80244, b: 79444, d: 237883 (total: 397571)\n",
      "local batches: 75 --  w: 3992, b: 3780, d: 11156\n",
      "local batches: 76 --  w: 4045, b: 3829, d: 11303\n",
      "local batches: 77 --  w: 4093, b: 3891, d: 11441\n",
      "local batches: 78 --  w: 4151, b: 3934, d: 11588\n",
      "local batches: 79 --  w: 4203, b: 3992, d: 11726\n",
      " -- global batches = 1613 --  w: 81468, b: 80708, d: 241600 (total: 403776)\n",
      "local batches: 80 --  w: 4266, b: 4058, d: 11845\n",
      "local batches: 81 --  w: 4317, b: 4130, d: 11970\n",
      "local batches: 82 --  w: 4365, b: 4190, d: 12110\n",
      "local batches: 83 --  w: 4420, b: 4254, d: 12239\n",
      "local batches: 84 --  w: 4457, b: 4314, d: 12390\n",
      " -- global batches = 1638 --  w: 82766, b: 82192, d: 245018 (total: 409976)\n",
      "local batches: 85 --  w: 4501, b: 4365, d: 12543\n",
      "local batches: 86 --  w: 4556, b: 4414, d: 12687\n",
      "local batches: 87 --  w: 4611, b: 4479, d: 12815\n",
      "local batches: 88 --  w: 4659, b: 4562, d: 12932\n",
      "local batches: 89 --  w: 4711, b: 4615, d: 13075\n",
      " -- global batches = 1664 --  w: 84111, b: 83693, d: 248620 (total: 416424)\n",
      "local batches: 90 --  w: 4771, b: 4673, d: 13205\n",
      "local batches: 91 --  w: 4806, b: 4728, d: 13363\n",
      "local batches: 92 --  w: 4858, b: 4789, d: 13498\n",
      "local batches: 93 --  w: 4908, b: 4838, d: 13647\n",
      "local batches: 94 --  w: 4962, b: 4900, d: 13779\n",
      " -- global batches = 1689 --  w: 85343, b: 85081, d: 252200 (total: 422624)\n",
      "local batches: 95 --  w: 5014, b: 4955, d: 13919\n",
      "local batches: 96 --  w: 5067, b: 4998, d: 14070\n",
      "local batches: 97 --  w: 5117, b: 5051, d: 14214\n",
      "local batches: 98 --  w: 5185, b: 5094, d: 14350\n",
      "local batches: 99 --  w: 5239, b: 5156, d: 14481\n",
      " -- global batches = 1714 --  w: 86679, b: 86462, d: 255662 (total: 428803)\n",
      "local batches: 100 --  w: 5292, b: 5200, d: 14631\n",
      "local batches: 101 --  w: 5359, b: 5264, d: 14747\n",
      "local batches: 102 --  w: 5404, b: 5334, d: 14879\n",
      "local batches: 103 --  w: 5450, b: 5389, d: 15025\n",
      "local batches: 104 --  w: 5507, b: 5444, d: 15160\n",
      " -- global batches = 1738 --  w: 87899, b: 87798, d: 259034 (total: 434731)\n",
      "local batches: 105 --  w: 5566, b: 5493, d: 15299\n",
      "local batches: 106 --  w: 5619, b: 5556, d: 15430\n",
      "local batches: 107 --  w: 5671, b: 5608, d: 15573\n",
      "local batches: 108 --  w: 5725, b: 5675, d: 15699\n",
      "local batches: 109 --  w: 5778, b: 5731, d: 15837\n",
      " -- global batches = 1763 --  w: 89268, b: 89149, d: 262489 (total: 440906)\n",
      "local batches: 110 --  w: 5830, b: 5794, d: 15969\n",
      "local batches: 111 --  w: 5885, b: 5853, d: 16102\n",
      "local batches: 112 --  w: 5937, b: 5913, d: 16236\n",
      "local batches: 113 --  w: 5980, b: 5973, d: 16379\n",
      "local batches: 114 --  w: 6033, b: 6038, d: 16507\n",
      " -- global batches = 1788 --  w: 90486, b: 90588, d: 265995 (total: 447069)\n",
      "local batches: 115 --  w: 6096, b: 6098, d: 16630\n",
      "local batches: 116 --  w: 6142, b: 6147, d: 16781\n",
      "local batches: 117 --  w: 6202, b: 6202, d: 16912\n",
      "local batches: 118 --  w: 6265, b: 6252, d: 17045\n",
      "local batches: 119 --  w: 6320, b: 6313, d: 17175\n",
      " -- global batches = 1813 --  w: 91832, b: 92008, d: 269379 (total: 453219)\n",
      "local batches: 120 --  w: 6368, b: 6380, d: 17306\n",
      "local batches: 121 --  w: 6425, b: 6439, d: 17436\n",
      "local batches: 122 --  w: 6479, b: 6489, d: 17578\n",
      "local batches: 123 --  w: 6542, b: 6544, d: 17706\n",
      "local batches: 124 --  w: 6596, b: 6602, d: 17840\n",
      " -- global batches = 1839 --  w: 93288, b: 93492, d: 272835 (total: 459615)\n",
      "local batches: 125 --  w: 6657, b: 6656, d: 17971\n",
      "local batches: 126 --  w: 6713, b: 6711, d: 18105\n",
      "local batches: 127 --  w: 6764, b: 6761, d: 18249\n",
      "local batches: 128 --  w: 6819, b: 6807, d: 18393\n",
      "local batches: 129 --  w: 6862, b: 6863, d: 18539\n",
      " -- global batches = 1863 --  w: 94609, b: 94812, d: 276082 (total: 465503)\n",
      "local batches: 130 --  w: 6921, b: 6915, d: 18673\n",
      "local batches: 131 --  w: 6982, b: 6971, d: 18801\n",
      "local batches: 132 --  w: 7043, b: 7024, d: 18932\n",
      "local batches: 133 --  w: 7095, b: 7079, d: 19070\n",
      "local batches: 134 --  w: 7163, b: 7133, d: 19193\n",
      " -- global batches = 1887 --  w: 95967, b: 96074, d: 279342 (total: 471383)\n",
      "local batches: 135 --  w: 7220, b: 7189, d: 19325\n",
      "local batches: 136 --  w: 7265, b: 7246, d: 19468\n",
      "local batches: 137 --  w: 7310, b: 7304, d: 19610\n",
      "local batches: 138 --  w: 7355, b: 7358, d: 19756\n",
      "local batches: 139 --  w: 7403, b: 7418, d: 19893\n",
      " -- global batches = 1912 --  w: 97246, b: 97415, d: 282847 (total: 477508)\n",
      "local batches: 140 --  w: 7458, b: 7473, d: 20028\n",
      "local batches: 141 --  w: 7515, b: 7512, d: 20177\n",
      "local batches: 142 --  w: 7567, b: 7557, d: 20325\n",
      "local batches: 143 --  w: 7639, b: 7613, d: 20442\n",
      "local batches: 144 --  w: 7693, b: 7669, d: 20577\n",
      " -- global batches = 1937 --  w: 98629, b: 98768, d: 286236 (total: 483633)\n",
      "local batches: 145 --  w: 7754, b: 7723, d: 20707\n",
      "local batches: 146 --  w: 7806, b: 7790, d: 20832\n",
      "local batches: 147 --  w: 7862, b: 7848, d: 20962\n",
      "local batches: 148 --  w: 7923, b: 7906, d: 21087\n",
      "local batches: 149 --  w: 7975, b: 7951, d: 21234\n",
      " -- global batches = 1962 --  w: 100089, b: 100139, d: 289510 (total: 489738)\n",
      "local batches: 150 --  w: 8043, b: 8004, d: 21357\n",
      "local batches: 151 --  w: 8110, b: 8056, d: 21482\n",
      "local batches: 152 --  w: 8168, b: 8128, d: 21596\n",
      "local batches: 153 --  w: 8223, b: 8190, d: 21723\n",
      "local batches: 154 --  w: 8275, b: 8248, d: 21857\n",
      " -- global batches = 1986 --  w: 101466, b: 101495, d: 292633 (total: 495594)\n",
      "local batches: 155 --  w: 8336, b: 8316, d: 21972\n",
      "local batches: 156 --  w: 8416, b: 8367, d: 22085\n",
      "local batches: 157 --  w: 8474, b: 8416, d: 22221\n",
      "local batches: 158 --  w: 8531, b: 8470, d: 22353\n",
      "local batches: 159 --  w: 8586, b: 8526, d: 22485\n",
      " -- global batches = 2012 --  w: 103018, b: 102951, d: 295954 (total: 501923)\n",
      "local batches: 160 --  w: 8643, b: 8580, d: 22617\n",
      "local batches: 161 --  w: 8698, b: 8626, d: 22759\n",
      "local batches: 162 --  w: 8749, b: 8680, d: 22897\n",
      "local batches: 163 --  w: 8817, b: 8730, d: 23022\n",
      "local batches: 164 --  w: 8867, b: 8788, d: 23157\n",
      " -- global batches = 2037 --  w: 104439, b: 104298, d: 299261 (total: 507998)\n",
      "local batches: 165 --  w: 8920, b: 8854, d: 23281\n",
      "local batches: 166 --  w: 8977, b: 8904, d: 23417\n",
      "local batches: 167 --  w: 9029, b: 8957, d: 23555\n",
      "local batches: 168 --  w: 9091, b: 9013, d: 23680\n",
      "local batches: 169 --  w: 9139, b: 9060, d: 23828\n",
      " -- global batches = 2062 --  w: 105794, b: 105647, d: 302632 (total: 514073)\n",
      "local batches: 170 --  w: 9191, b: 9117, d: 23962\n",
      "local batches: 171 --  w: 9256, b: 9168, d: 24089\n",
      "local batches: 172 --  w: 9310, b: 9224, d: 24222\n",
      "local batches: 173 --  w: 9363, b: 9275, d: 24360\n",
      "local batches: 174 --  w: 9420, b: 9329, d: 24491\n",
      " -- global batches = 2087 --  w: 107269, b: 107009, d: 305861 (total: 520139)\n",
      "local batches: 175 --  w: 9474, b: 9387, d: 24621\n",
      "local batches: 176 --  w: 9524, b: 9431, d: 24769\n",
      "local batches: 177 --  w: 9567, b: 9494, d: 24905\n",
      "local batches: 178 --  w: 9618, b: 9546, d: 25044\n",
      "local batches: 179 --  w: 9681, b: 9607, d: 25162\n",
      " -- global batches = 2112 --  w: 108603, b: 108341, d: 309245 (total: 526189)\n",
      "local batches: 180 --  w: 9741, b: 9677, d: 25274\n",
      "local batches: 181 --  w: 9803, b: 9721, d: 25410\n",
      "local batches: 182 --  w: 9858, b: 9766, d: 25552\n",
      "local batches: 183 --  w: 9902, b: 9819, d: 25697\n",
      "local batches: 184 --  w: 9953, b: 9873, d: 25834\n",
      " -- global batches = 2137 --  w: 109992, b: 109683, d: 312564 (total: 532239)\n",
      "local batches: 185 --  w: 9995, b: 9925, d: 25982\n",
      "local batches: 186 --  w: 10050, b: 9976, d: 26118\n",
      "local batches: 187 --  w: 10106, b: 10030, d: 26250\n",
      "local batches: 188 --  w: 10154, b: 10089, d: 26385\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/Philip/Desktop/GitHub/ChessEngine/Train Value Function/Monte Carlo/ValueTrain_MC_v8_ParBatched_2.ipynb Cell 6\u001b[0m line \u001b[0;36m7\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Philip/Desktop/GitHub/ChessEngine/Train%20Value%20Function/Monte%20Carlo/ValueTrain_MC_v8_ParBatched_2.ipynb#X15sZmlsZQ%3D%3D?line=68'>69</a>\u001b[0m board_batch\u001b[39m.\u001b[39mappend(board_to_tensor(game\u001b[39m.\u001b[39mpieces))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Philip/Desktop/GitHub/ChessEngine/Train%20Value%20Function/Monte%20Carlo/ValueTrain_MC_v8_ParBatched_2.ipynb#X15sZmlsZQ%3D%3D?line=69'>70</a>\u001b[0m game\u001b[39m.\u001b[39mFlipBoard()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/Philip/Desktop/GitHub/ChessEngine/Train%20Value%20Function/Monte%20Carlo/ValueTrain_MC_v8_ParBatched_2.ipynb#X15sZmlsZQ%3D%3D?line=70'>71</a>\u001b[0m \u001b[39mif\u001b[39;00m game\u001b[39m.\u001b[39;49mis_over():\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Philip/Desktop/GitHub/ChessEngine/Train%20Value%20Function/Monte%20Carlo/ValueTrain_MC_v8_ParBatched_2.ipynb#X15sZmlsZQ%3D%3D?line=71'>72</a>\u001b[0m     mate \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Philip/Desktop/GitHub/ChessEngine/Train%20Value%20Function/Monte%20Carlo/ValueTrain_MC_v8_ParBatched_2.ipynb#X15sZmlsZQ%3D%3D?line=72'>73</a>\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/GitHub/ChessEngine/Resources/Game.py:100\u001b[0m, in \u001b[0;36mGame.is_over\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[39mif\u001b[39;00m (tot \u001b[39m==\u001b[39m \u001b[39m22\u001b[39m\u001b[39m+\u001b[39m\u001b[39m2\u001b[39m \u001b[39mand\u001b[39;00m piece_counts[\u001b[39m2\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m) \u001b[39mor\u001b[39;00m (tot \u001b[39m==\u001b[39m \u001b[39m22\u001b[39m\u001b[39m+\u001b[39m\u001b[39m12\u001b[39m \u001b[39mand\u001b[39;00m piece_counts[\u001b[39m12\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[1;32m     98\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m--> 100\u001b[0m moves \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mPossibleMoves()\n\u001b[1;32m    102\u001b[0m \u001b[39m# No moves available -> stalemate or checkmate\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(moves) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m: \n",
      "File \u001b[0;32m~/Desktop/GitHub/ChessEngine/Resources/Game.py:881\u001b[0m, in \u001b[0;36mGame.PossibleMoves\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpieces[king] \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    880\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpieces[test_pos] \u001b[39m=\u001b[39m \u001b[39m6\u001b[39m\n\u001b[0;32m--> 881\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mInCheck_pieces(opp_pawns, opp_knights, opp_bishops, opp_rooks, \n\u001b[1;32m    882\u001b[0m                            opp_queens, test_pos, opp_king):\n\u001b[1;32m    883\u001b[0m     playable_moves\u001b[39m.\u001b[39mappend((king, test_pos, \u001b[39m'\u001b[39m\u001b[39mking\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[1;32m    884\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpieces[king] \u001b[39m=\u001b[39m \u001b[39m6\u001b[39m\n",
      "File \u001b[0;32m~/Desktop/GitHub/ChessEngine/Resources/Game.py:259\u001b[0m, in \u001b[0;36mGame.InCheck_pieces\u001b[0;34m(self, pawns, knights, bishops, rooks, queens, king, opp_king, pos)\u001b[0m\n\u001b[1;32m    255\u001b[0m                         \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    257\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m--> 259\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mInCheck_pieces\u001b[39m(\u001b[39mself\u001b[39m, pawns, knights, bishops, rooks, queens, king, opp_king, pos \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    260\u001b[0m \u001b[39m    \u001b[39m\u001b[39m'''\u001b[39;00m\n\u001b[1;32m    261\u001b[0m \u001b[39m    version of in check where positions of opponent's pieces are given\u001b[39;00m\n\u001b[1;32m    262\u001b[0m \u001b[39m    Used in PossibleMoves for efficient playability test of potential moves\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[39m    940329\u001b[39;00m\n\u001b[1;32m    275\u001b[0m \u001b[39m    '''\u001b[39;00m\n\u001b[1;32m    277\u001b[0m     \u001b[39mif\u001b[39;00m pos \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# keep generating new batches of data until stopped\n",
    "while True:\n",
    "\n",
    "    batch_white_wins = 0\n",
    "    batch_black_wins = 0\n",
    "    batch_draws = 0\n",
    "\n",
    "    # load newest model\n",
    "    model = Model_v8()\n",
    "    model_saves = os.listdir('../Monte Carlo/Model Saves MC v8_3')\n",
    "    if len(model_saves) > 0:\n",
    "        newest_model = max(int(i[6:-8]) for i in model_saves)\n",
    "        model.load_state_dict(torch.load('../Monte Carlo/Model Saves MC v8_3/model_{}_batches'.format(newest_model)))\n",
    "    else:\n",
    "        time.sleep(0.05)\n",
    "\n",
    "    # print('loaded model ', newest_model)\n",
    "\n",
    "    with open('/Users/Philip/Desktop/Projects/RL Chess/MCTS/Game Saves v8_3/stats', 'rb') as f:\n",
    "        stats = torch.load(f)\n",
    "    stats = stats.int()\n",
    "    global_white_wins   = stats[1]\n",
    "    global_black_wins   = stats[2]\n",
    "    global_draws        = stats[3]\n",
    "\n",
    "    percentage_decisive = (global_white_wins + global_black_wins) / (global_white_wins + global_black_wins + global_draws)\n",
    "    batch_size = int(batch_target // percentage_decisive.item()) # so that on average we have [batch_target] decisive games\n",
    "\n",
    "    meta_games = []\n",
    "    meta_boards_white = []; meta_boards_black = []\n",
    "    i = 0\n",
    "\n",
    "    meta_active = []\n",
    "\n",
    "    for game_ind in range(batch_size):\n",
    "        meta_games.append( Game() )\n",
    "        meta_boards_white.append([]); meta_boards_black.append([])\n",
    "        meta_active.append(True)\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    # print('start with {} games'.format(batch_size))\n",
    "\n",
    "    while True in meta_active:\n",
    "\n",
    "        # if i % 20 == 0:\n",
    "        #     print('i = {}, with {} active games '.format(i, meta_active.count(True)))\n",
    "\n",
    "        i += 1\n",
    "        full_board_batch = []\n",
    "        meta_board_batch_sizes = [] # save batch sizes to split model output afterwards\n",
    "        meta_moves = []\n",
    "\n",
    "        # go through games, collect positions for value evaluations\n",
    "        for g, game in enumerate(meta_games):\n",
    "\n",
    "            if not meta_active[g]:\n",
    "                meta_board_batch_sizes.append(0)\n",
    "                meta_moves.append([])\n",
    "                continue\n",
    "\n",
    "            meta_moves.append(game.PossibleMoves())\n",
    "            game_ini = game.copy()\n",
    "            board_batch = [board_to_tensor(game.pieces)]\n",
    "            mate = False\n",
    "\n",
    "            for move in meta_moves[-1]:\n",
    "                game.PlayMove(move)\n",
    "                board_batch.append(board_to_tensor(game.pieces))\n",
    "                game.FlipBoard()\n",
    "                if game.is_over():\n",
    "                    mate = True\n",
    "                    break\n",
    "                game = game_ini.copy()\n",
    "\n",
    "            meta_games[g] = game.copy()\n",
    "\n",
    "            if mate:\n",
    "                meta_active[g] = False\n",
    "                meta_board_batch_sizes.append(0)\n",
    "                game.FlipBoard()\n",
    "                if i % 2 == 1:\n",
    "                    meta_boards_white[g].append(board_to_bool_tensor(game.pieces))\n",
    "                if i % 2 == 0:\n",
    "                    meta_boards_black[g].append(board_to_bool_tensor(game.pieces))\n",
    "\n",
    "            if not mate:\n",
    "                full_board_batch = full_board_batch + board_batch\n",
    "                meta_board_batch_sizes.append(len(board_batch))\n",
    "\n",
    "        if len(full_board_batch) == 0:\n",
    "            break\n",
    "\n",
    "        # get values of all positions\n",
    "        full_board_batch = torch.stack(full_board_batch)\n",
    "        out = model(full_board_batch).detach()\n",
    "        meta_values = torch.split(out, meta_board_batch_sizes)\n",
    "\n",
    "        # make moves for all games\n",
    "        for g, game in enumerate(meta_games):\n",
    "\n",
    "            if not meta_active[g]:\n",
    "                continue\n",
    "            values = meta_values[g]\n",
    "            if i < 7:\n",
    "                scale = value_diff_scale_early\n",
    "            else:\n",
    "                scale = value_diff_scale\n",
    "            values_diff = [scale*(values[i] - values[0]) for i in range(1, len(values))]\n",
    "            move_prob = torch.softmax(torch.Tensor(values_diff), dim=0).numpy()\n",
    "            chosen_i = np.random.choice(range(len(meta_moves[g])), p=move_prob)\n",
    "            chosen_move = meta_moves[g][chosen_i]\n",
    "            game.PlayMove(chosen_move)\n",
    "            if i % 2 == 1:\n",
    "                meta_boards_white[g].append(board_to_bool_tensor(game.pieces))\n",
    "            if i % 2 == 0:\n",
    "                meta_boards_black[g].append(board_to_bool_tensor(game.pieces))\n",
    "            game.FlipBoard()\n",
    "\n",
    "    # print('games done, start evaluating')\n",
    "\n",
    "    meta_inputs = []\n",
    "    meta_labels = []\n",
    "\n",
    "    for g, game in enumerate(meta_games):\n",
    "        \n",
    "        winner = game.get_winner()\n",
    "        if winner == 'draw':\n",
    "            draws += 1; batch_draws += 1\n",
    "            continue\n",
    "            reward_white = 0;   reward_black = 0\n",
    "\n",
    "        elif winner == 'white':\n",
    "            white_wins += 1; batch_white_wins += 1\n",
    "            reward_white = 1;   reward_black = -1\n",
    "\n",
    "        elif winner == 'black':\n",
    "            black_wins += 1; batch_black_wins += 1\n",
    "            reward_white = -1;  reward_black = 1\n",
    "\n",
    "        labels_white = [reward_white * gamma**(len(meta_boards_white[g]) - 1 - i) for i in range(len(meta_boards_white[g]))]\n",
    "        labels_black = [reward_black * gamma**(len(meta_boards_black[g]) - 1 - i) for i in range(len(meta_boards_black[g]))]\n",
    "\n",
    "        meta_inputs = meta_inputs + meta_boards_white[g] + meta_boards_black[g]\n",
    "        meta_labels = meta_labels + labels_white + labels_black\n",
    "\n",
    "    if batch_white_wins + batch_black_wins == 0:\n",
    "        print('no decisive games in the whole batch -> skip to next batch (batch size too small?)')\n",
    "        continue\n",
    "\n",
    "    inputs_tens = torch.stack(meta_inputs)\n",
    "    labels_tens = torch.Tensor(meta_labels)\n",
    "\n",
    "    # print('evaluation done, save batch')\n",
    "\n",
    "    with open('/Users/Philip/Desktop/Projects/RL Chess/MCTS/Game Saves v8_3/stats', 'rb') as f:\n",
    "        stats = torch.load(f)\n",
    "    stats = stats.int()\n",
    "    stats[0] += 1;                  stats[1] += batch_white_wins\n",
    "    stats[2] += batch_black_wins;   stats[3] += batch_draws\n",
    "    torch.save(stats, '/Users/Philip/Desktop/Projects/RL Chess/MCTS/Game Saves v8_3/stats')\n",
    "\n",
    "    # print('batch index = ', stats[0])\n",
    "\n",
    "    new_batch_index = stats[0]\n",
    "    torch.save(inputs_tens, '/Users/Philip/Desktop/Projects/RL Chess/MCTS/Game Saves v8_3/inputs_{}'.format(new_batch_index))\n",
    "    torch.save(labels_tens, '/Users/Philip/Desktop/Projects/RL Chess/MCTS/Game Saves v8_3/labels_{}'.format(new_batch_index))\n",
    "\n",
    "    print('local batches: {} --  w: {}, b: {}, d: {}'.format(batch_count, white_wins, black_wins, draws))\n",
    "\n",
    "    batch_count += 1\n",
    "\n",
    "    if batch_count % 5 == 0:\n",
    "        print(' -- global batches = {} --  w: {}, b: {}, d: {} (total: {})'.format(\n",
    "            new_batch_index, stats[1], stats[2], stats[3], stats[1] + stats[2] + stats[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
