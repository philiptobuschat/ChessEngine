{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import sys, os\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "sys.path.append(project_root)\n",
    "\n",
    "from Resources.Model import Model_v28\n",
    "from Resources.Game import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### global parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 0.98\n",
    "\n",
    "def scale(i):\n",
    "    return i**2\n",
    "\n",
    "# games saved in batches to reduce i/o stream\n",
    "# each batch is a input file and a label file containing [batch_size] individual games\n",
    "batch_target = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### local counters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "white_wins = 0\n",
    "black_wins = 0\n",
    "draws = 0\n",
    "\n",
    "batch_count = 0         # number of batches locally done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local batches: 0 --  w: 99, b: 102, d: 295\n",
      "local batches: 1 --  w: 194, b: 177, d: 621\n",
      "local batches: 2 --  w: 291, b: 263, d: 935\n",
      "local batches: 3 --  w: 389, b: 342, d: 1255\n",
      "local batches: 4 --  w: 488, b: 433, d: 1562\n",
      " -- global batches = 802 --  w: 78165, b: 76205, d: 229704 (total: 384074)\n",
      "local batches: 5 --  w: 588, b: 530, d: 1862\n",
      "local batches: 6 --  w: 691, b: 608, d: 2178\n",
      "local batches: 7 --  w: 801, b: 713, d: 2460\n",
      "local batches: 8 --  w: 896, b: 827, d: 2748\n",
      "local batches: 9 --  w: 1015, b: 909, d: 3044\n",
      " -- global batches = 817 --  w: 79653, b: 77628, d: 234248 (total: 391529)\n",
      "local batches: 10 --  w: 1124, b: 1001, d: 3340\n",
      "local batches: 11 --  w: 1222, b: 1091, d: 3649\n",
      "local batches: 12 --  w: 1318, b: 1188, d: 3953\n",
      "local batches: 13 --  w: 1412, b: 1272, d: 4273\n",
      "local batches: 14 --  w: 1511, b: 1389, d: 4555\n",
      " -- global batches = 831 --  w: 81009, b: 78994, d: 238488 (total: 398491)\n",
      "local batches: 15 --  w: 1614, b: 1493, d: 4846\n",
      "local batches: 16 --  w: 1708, b: 1589, d: 5154\n",
      "local batches: 17 --  w: 1797, b: 1672, d: 5480\n",
      "local batches: 18 --  w: 1885, b: 1762, d: 5800\n",
      "local batches: 19 --  w: 1989, b: 1851, d: 6105\n",
      " -- global batches = 846 --  w: 82468, b: 80369, d: 243123 (total: 405960)\n",
      "local batches: 20 --  w: 2072, b: 1949, d: 6422\n",
      "local batches: 21 --  w: 2190, b: 2026, d: 6725\n",
      "local batches: 22 --  w: 2293, b: 2123, d: 7023\n",
      "local batches: 23 --  w: 2397, b: 2223, d: 7317\n",
      "local batches: 24 --  w: 2501, b: 2307, d: 7628\n",
      " -- global batches = 861 --  w: 83899, b: 81758, d: 247775 (total: 413432)\n",
      "local batches: 25 --  w: 2573, b: 2410, d: 7952\n",
      "local batches: 26 --  w: 2664, b: 2506, d: 8264\n",
      "local batches: 27 --  w: 2749, b: 2597, d: 8587\n",
      "local batches: 28 --  w: 2853, b: 2686, d: 8893\n",
      "local batches: 29 --  w: 2940, b: 2759, d: 9232\n",
      " -- global batches = 876 --  w: 85346, b: 83099, d: 252472 (total: 420917)\n",
      "local batches: 30 --  w: 3039, b: 2852, d: 9539\n",
      "local batches: 31 --  w: 3125, b: 2938, d: 9866\n",
      "local batches: 32 --  w: 3228, b: 3024, d: 10177\n",
      "local batches: 33 --  w: 3305, b: 3125, d: 10499\n",
      "local batches: 34 --  w: 3392, b: 3221, d: 10816\n",
      " -- global batches = 891 --  w: 86739, b: 84504, d: 257166 (total: 428409)\n",
      "local batches: 35 --  w: 3485, b: 3316, d: 11128\n",
      "local batches: 36 --  w: 3588, b: 3406, d: 11435\n",
      "local batches: 37 --  w: 3688, b: 3501, d: 11740\n",
      "local batches: 38 --  w: 3777, b: 3599, d: 12053\n",
      "local batches: 39 --  w: 3871, b: 3687, d: 12371\n",
      " -- global batches = 906 --  w: 88207, b: 85914, d: 261788 (total: 435909)\n",
      "local batches: 40 --  w: 3972, b: 3788, d: 12669\n",
      "local batches: 41 --  w: 4065, b: 3866, d: 12998\n",
      "local batches: 42 --  w: 4166, b: 3976, d: 13287\n",
      "local batches: 43 --  w: 4254, b: 4066, d: 13609\n",
      "local batches: 44 --  w: 4367, b: 4158, d: 13905\n",
      " -- global batches = 921 --  w: 89654, b: 87336, d: 266422 (total: 443412)\n",
      "local batches: 45 --  w: 4463, b: 4245, d: 14223\n",
      "local batches: 46 --  w: 4541, b: 4341, d: 14550\n",
      "local batches: 47 --  w: 4621, b: 4428, d: 14884\n",
      "local batches: 48 --  w: 4718, b: 4534, d: 15182\n",
      "local batches: 49 --  w: 4813, b: 4629, d: 15493\n",
      " -- global batches = 936 --  w: 91076, b: 88732, d: 271119 (total: 450927)\n",
      "local batches: 50 --  w: 4917, b: 4720, d: 15799\n",
      "local batches: 51 --  w: 5017, b: 4805, d: 16115\n",
      "local batches: 52 --  w: 5113, b: 4898, d: 16427\n",
      "local batches: 53 --  w: 5214, b: 5011, d: 16714\n",
      "local batches: 54 --  w: 5322, b: 5110, d: 17008\n",
      " -- global batches = 951 --  w: 92506, b: 90147, d: 275790 (total: 458443)\n",
      "local batches: 55 --  w: 5416, b: 5214, d: 17311\n",
      "local batches: 56 --  w: 5517, b: 5315, d: 17610\n",
      "local batches: 57 --  w: 5594, b: 5415, d: 17934\n",
      "local batches: 58 --  w: 5688, b: 5518, d: 18239\n",
      "local batches: 59 --  w: 5774, b: 5605, d: 18568\n",
      " -- global batches = 966 --  w: 93906, b: 91645, d: 280416 (total: 465967)\n",
      "local batches: 60 --  w: 5855, b: 5706, d: 18888\n",
      "local batches: 61 --  w: 5953, b: 5807, d: 19191\n",
      "local batches: 62 --  w: 6048, b: 5916, d: 19489\n",
      "local batches: 63 --  w: 6139, b: 6013, d: 19803\n",
      "local batches: 64 --  w: 6225, b: 6105, d: 20127\n",
      " -- global batches = 981 --  w: 95266, b: 93070, d: 285161 (total: 473497)\n",
      "local batches: 65 --  w: 6304, b: 6212, d: 20443\n",
      "local batches: 66 --  w: 6404, b: 6289, d: 20768\n",
      "local batches: 67 --  w: 6488, b: 6378, d: 21098\n",
      "local batches: 68 --  w: 6586, b: 6469, d: 21412\n",
      "local batches: 69 --  w: 6681, b: 6572, d: 21717\n",
      " -- global batches = 996 --  w: 96681, b: 94478, d: 289875 (total: 481034)\n",
      "local batches: 70 --  w: 6792, b: 6676, d: 22005\n",
      "local batches: 71 --  w: 6878, b: 6756, d: 22342\n",
      "local batches: 72 --  w: 6959, b: 6845, d: 22675\n",
      "local batches: 73 --  w: 7043, b: 6938, d: 23001\n",
      "local batches: 74 --  w: 7138, b: 7018, d: 23329\n",
      " -- global batches = 1011 --  w: 98092, b: 95870, d: 294617 (total: 488579)\n",
      "local batches: 75 --  w: 7242, b: 7110, d: 23636\n",
      "local batches: 76 --  w: 7345, b: 7197, d: 23949\n",
      "local batches: 77 --  w: 7425, b: 7294, d: 24275\n",
      "local batches: 78 --  w: 7512, b: 7389, d: 24596\n",
      "local batches: 79 --  w: 7612, b: 7486, d: 24902\n",
      " -- global batches = 1026 --  w: 99589, b: 97282, d: 299253 (total: 496124)\n",
      "local batches: 80 --  w: 7700, b: 7588, d: 25216\n",
      "local batches: 81 --  w: 7806, b: 7682, d: 25520\n",
      "local batches: 82 --  w: 7908, b: 7773, d: 25831\n",
      "local batches: 83 --  w: 8003, b: 7868, d: 26145\n",
      "local batches: 84 --  w: 8079, b: 7967, d: 26474\n",
      " -- global batches = 1041 --  w: 101069, b: 98722, d: 303893 (total: 503684)\n",
      "local batches: 85 --  w: 8149, b: 8081, d: 26794\n",
      "local batches: 86 --  w: 8240, b: 8187, d: 27101\n",
      "local batches: 87 --  w: 8333, b: 8276, d: 27423\n",
      "local batches: 88 --  w: 8418, b: 8381, d: 27737\n",
      "local batches: 89 --  w: 8510, b: 8471, d: 28059\n",
      " -- global batches = 1056 --  w: 102423, b: 100181, d: 308640 (total: 511244)\n",
      "local batches: 90 --  w: 8608, b: 8583, d: 28353\n",
      "local batches: 91 --  w: 8722, b: 8673, d: 28653\n",
      "local batches: 92 --  w: 8808, b: 8764, d: 28980\n",
      "local batches: 93 --  w: 8909, b: 8849, d: 29298\n",
      "local batches: 94 --  w: 8981, b: 8942, d: 29637\n",
      " -- global batches = 1071 --  w: 103858, b: 101557, d: 313389 (total: 518804)\n",
      "local batches: 95 --  w: 9072, b: 9022, d: 29971\n",
      "local batches: 96 --  w: 9165, b: 9112, d: 30293\n",
      "local batches: 97 --  w: 9256, b: 9212, d: 30607\n",
      "local batches: 98 --  w: 9339, b: 9304, d: 30937\n",
      "local batches: 99 --  w: 9424, b: 9395, d: 31266\n",
      " -- global batches = 1086 --  w: 105206, b: 102930, d: 318243 (total: 526379)\n",
      "local batches: 100 --  w: 9531, b: 9478, d: 31581\n",
      "local batches: 101 --  w: 9629, b: 9579, d: 31887\n",
      "local batches: 102 --  w: 9727, b: 9675, d: 32198\n",
      "local batches: 103 --  w: 9835, b: 9774, d: 32496\n",
      "local batches: 104 --  w: 9921, b: 9863, d: 32826\n",
      " -- global batches = 1101 --  w: 106623, b: 104392, d: 322939 (total: 533954)\n",
      "local batches: 105 --  w: 9999, b: 9969, d: 33148\n",
      "local batches: 106 --  w: 10093, b: 10065, d: 33464\n",
      "local batches: 107 --  w: 10195, b: 10161, d: 33772\n",
      "local batches: 108 --  w: 10276, b: 10241, d: 34117\n",
      "local batches: 109 --  w: 10357, b: 10340, d: 34443\n",
      " -- global batches = 1115 --  w: 107849, b: 105654, d: 327534 (total: 541037)\n",
      "local batches: 110 --  w: 10449, b: 10434, d: 34763\n",
      "local batches: 111 --  w: 10544, b: 10516, d: 35092\n",
      "local batches: 112 --  w: 10628, b: 10595, d: 35436\n",
      "local batches: 113 --  w: 10707, b: 10687, d: 35772\n",
      "local batches: 114 --  w: 10820, b: 10774, d: 36079\n",
      " -- global batches = 1130 --  w: 109254, b: 106943, d: 332438 (total: 548635)\n",
      "local batches: 115 --  w: 10920, b: 10865, d: 36395\n",
      "local batches: 116 --  w: 11006, b: 10957, d: 36724\n",
      "local batches: 117 --  w: 11087, b: 11040, d: 37067\n",
      "local batches: 118 --  w: 11204, b: 11118, d: 37379\n",
      "local batches: 119 --  w: 11289, b: 11218, d: 37702\n",
      " -- global batches = 1145 --  w: 110614, b: 108304, d: 337325 (total: 556243)\n",
      "local batches: 120 --  w: 11385, b: 11292, d: 38040\n",
      "local batches: 121 --  w: 11467, b: 11382, d: 38376\n",
      "local batches: 122 --  w: 11564, b: 11459, d: 38710\n",
      "local batches: 123 --  w: 11646, b: 11554, d: 39041\n",
      "local batches: 124 --  w: 11715, b: 11640, d: 39394\n",
      " -- global batches = 1160 --  w: 111931, b: 109627, d: 342305 (total: 563863)\n",
      "local batches: 125 --  w: 11807, b: 11722, d: 39728\n",
      "local batches: 126 --  w: 11891, b: 11819, d: 40056\n",
      "local batches: 127 --  w: 11970, b: 11904, d: 40401\n",
      "local batches: 128 --  w: 12047, b: 12003, d: 40734\n",
      "local batches: 129 --  w: 12136, b: 12087, d: 41070\n",
      " -- global batches = 1175 --  w: 113267, b: 111019, d: 347209 (total: 571495)\n",
      "local batches: 130 --  w: 12220, b: 12184, d: 41398\n",
      "local batches: 131 --  w: 12306, b: 12281, d: 41724\n",
      "local batches: 132 --  w: 12390, b: 12378, d: 42052\n",
      "local batches: 133 --  w: 12479, b: 12470, d: 42381\n",
      "local batches: 134 --  w: 12564, b: 12549, d: 42727\n",
      " -- global batches = 1190 --  w: 114619, b: 112369, d: 352146 (total: 579134)\n",
      "local batches: 135 --  w: 12653, b: 12635, d: 43062\n",
      "local batches: 136 --  w: 12743, b: 12723, d: 43394\n",
      "local batches: 137 --  w: 12817, b: 12808, d: 43745\n",
      "local batches: 138 --  w: 12927, b: 12887, d: 44066\n",
      "local batches: 139 --  w: 13017, b: 12965, d: 44408\n",
      " -- global batches = 1205 --  w: 115970, b: 113676, d: 357138 (total: 586784)\n",
      "local batches: 140 --  w: 13109, b: 13042, d: 44750\n",
      "local batches: 141 --  w: 13190, b: 13120, d: 45102\n",
      "local batches: 142 --  w: 13274, b: 13213, d: 45436\n",
      "local batches: 143 --  w: 13359, b: 13301, d: 45774\n",
      "local batches: 144 --  w: 13461, b: 13377, d: 46107\n",
      " -- global batches = 1220 --  w: 117253, b: 115014, d: 362180 (total: 594447)\n",
      "local batches: 145 --  w: 13547, b: 13477, d: 46432\n",
      "local batches: 146 --  w: 13626, b: 13553, d: 46788\n",
      "local batches: 147 --  w: 13708, b: 13650, d: 47121\n",
      "local batches: 148 --  w: 13804, b: 13754, d: 47433\n",
      "local batches: 149 --  w: 13885, b: 13846, d: 47772\n",
      " -- global batches = 1235 --  w: 118571, b: 116343, d: 367207 (total: 602121)\n",
      "local batches: 150 --  w: 13967, b: 13928, d: 48120\n",
      "local batches: 151 --  w: 14046, b: 14034, d: 48447\n",
      "local batches: 152 --  w: 14137, b: 14128, d: 48774\n",
      "local batches: 153 --  w: 14238, b: 14221, d: 49093\n",
      "local batches: 154 --  w: 14332, b: 14299, d: 49434\n",
      " -- global batches = 1250 --  w: 119960, b: 117720, d: 372126 (total: 609806)\n",
      "local batches: 155 --  w: 14416, b: 14389, d: 49773\n",
      "local batches: 156 --  w: 14511, b: 14483, d: 50097\n",
      "local batches: 157 --  w: 14615, b: 14568, d: 50421\n",
      "local batches: 158 --  w: 14712, b: 14653, d: 50752\n",
      "local batches: 159 --  w: 14805, b: 14722, d: 51103\n",
      " -- global batches = 1266 --  w: 121477, b: 119201, d: 377336 (total: 618014)\n",
      "local batches: 160 --  w: 14886, b: 14824, d: 51433\n",
      "local batches: 161 --  w: 14974, b: 14912, d: 51770\n",
      "local batches: 162 --  w: 15069, b: 15009, d: 52091\n",
      "local batches: 163 --  w: 15167, b: 15099, d: 52416\n",
      "local batches: 164 --  w: 15261, b: 15175, d: 52760\n",
      " -- global batches = 1281 --  w: 122837, b: 120532, d: 382343 (total: 625712)\n",
      "local batches: 165 --  w: 15359, b: 15280, d: 53071\n",
      "local batches: 166 --  w: 15460, b: 15360, d: 53404\n",
      "local batches: 167 --  w: 15547, b: 15456, d: 53735\n",
      "local batches: 168 --  w: 15641, b: 15541, d: 54070\n",
      "local batches: 169 --  w: 15747, b: 15648, d: 54371\n",
      " -- global batches = 1295 --  w: 124203, b: 121787, d: 386918 (total: 632908)\n",
      "local batches: 170 --  w: 15839, b: 15732, d: 54709\n",
      "local batches: 171 --  w: 15937, b: 15817, d: 55040\n",
      "local batches: 172 --  w: 16031, b: 15897, d: 55380\n",
      "local batches: 173 --  w: 16101, b: 15996, d: 55725\n",
      "local batches: 174 --  w: 16189, b: 16091, d: 56057\n",
      " -- global batches = 1310 --  w: 125597, b: 123080, d: 391944 (total: 640621)\n",
      "local batches: 175 --  w: 16265, b: 16184, d: 56403\n",
      "local batches: 176 --  w: 16359, b: 16284, d: 56724\n",
      "local batches: 177 --  w: 16459, b: 16383, d: 57040\n",
      "local batches: 178 --  w: 16537, b: 16476, d: 57384\n",
      "local batches: 179 --  w: 16636, b: 16564, d: 57712\n",
      " -- global batches = 1325 --  w: 126964, b: 124493, d: 396889 (total: 648346)\n",
      "local batches: 180 --  w: 16734, b: 16646, d: 58047\n",
      "local batches: 181 --  w: 16833, b: 16738, d: 58371\n",
      "local batches: 182 --  w: 16917, b: 16828, d: 58712\n",
      "local batches: 183 --  w: 17013, b: 16917, d: 59042\n",
      "local batches: 184 --  w: 17093, b: 17016, d: 59379\n",
      " -- global batches = 1340 --  w: 128344, b: 125886, d: 401843 (total: 656073)\n",
      "local batches: 185 --  w: 17182, b: 17108, d: 59714\n",
      "local batches: 186 --  w: 17268, b: 17200, d: 60052\n",
      "local batches: 187 --  w: 17372, b: 17290, d: 60374\n",
      "local batches: 188 --  w: 17457, b: 17387, d: 60708\n",
      "local batches: 189 --  w: 17550, b: 17486, d: 61032\n",
      " -- global batches = 1354 --  w: 129584, b: 127202, d: 406511 (total: 663297)\n",
      "local batches: 190 --  w: 17645, b: 17591, d: 61348\n",
      "local batches: 191 --  w: 17753, b: 17673, d: 61674\n",
      "local batches: 192 --  w: 17830, b: 17782, d: 62004\n",
      "local batches: 193 --  w: 17921, b: 17867, d: 62344\n",
      "local batches: 194 --  w: 18009, b: 17949, d: 62690\n",
      " -- global batches = 1370 --  w: 131112, b: 128700, d: 411741 (total: 671553)\n",
      "local batches: 195 --  w: 18106, b: 18053, d: 63005\n",
      "local batches: 196 --  w: 18196, b: 18149, d: 63335\n",
      "local batches: 197 --  w: 18295, b: 18233, d: 63669\n",
      "local batches: 198 --  w: 18401, b: 18316, d: 63997\n",
      "local batches: 199 --  w: 18505, b: 18404, d: 64322\n",
      " -- global batches = 1385 --  w: 132604, b: 130091, d: 416606 (total: 679301)\n",
      "local batches: 200 --  w: 18609, b: 18503, d: 64636\n",
      "local batches: 201 --  w: 18694, b: 18595, d: 64976\n",
      "local batches: 202 --  w: 18792, b: 18669, d: 65321\n",
      "local batches: 203 --  w: 18886, b: 18764, d: 65649\n",
      "local batches: 204 --  w: 18988, b: 18866, d: 65962\n",
      " -- global batches = 1400 --  w: 133982, b: 131539, d: 421535 (total: 687056)\n",
      "local batches: 205 --  w: 19093, b: 18963, d: 66277\n",
      "local batches: 206 --  w: 19182, b: 19044, d: 66624\n",
      "local batches: 207 --  w: 19281, b: 19129, d: 66957\n",
      "local batches: 208 --  w: 19377, b: 19231, d: 67276\n",
      "local batches: 209 --  w: 19474, b: 19321, d: 67606\n",
      " -- global batches = 1415 --  w: 135395, b: 132939, d: 426477 (total: 694811)\n",
      "local batches: 210 --  w: 19560, b: 19400, d: 67958\n",
      "local batches: 211 --  w: 19648, b: 19508, d: 68280\n",
      "local batches: 212 --  w: 19749, b: 19599, d: 68606\n",
      "local batches: 213 --  w: 19833, b: 19672, d: 68967\n",
      "local batches: 214 --  w: 19915, b: 19755, d: 69320\n",
      " -- global batches = 1430 --  w: 136747, b: 134251, d: 431578 (total: 702576)\n",
      "local batches: 215 --  w: 19996, b: 19849, d: 69663\n",
      "local batches: 216 --  w: 20083, b: 19941, d: 70002\n",
      "local batches: 217 --  w: 20178, b: 20033, d: 70333\n",
      "local batches: 218 --  w: 20274, b: 20107, d: 70681\n",
      "local batches: 219 --  w: 20358, b: 20194, d: 71028\n",
      " -- global batches = 1445 --  w: 138117, b: 135569, d: 436660 (total: 710346)\n",
      "local batches: 220 --  w: 20453, b: 20276, d: 71370\n",
      "local batches: 221 --  w: 20553, b: 20360, d: 71705\n",
      "local batches: 222 --  w: 20641, b: 20446, d: 72050\n",
      "local batches: 223 --  w: 20732, b: 20531, d: 72393\n",
      "local batches: 224 --  w: 20842, b: 20611, d: 72722\n",
      " -- global batches = 1460 --  w: 139533, b: 136868, d: 441730 (total: 718131)\n",
      "local batches: 225 --  w: 20924, b: 20713, d: 73057\n",
      "local batches: 226 --  w: 21017, b: 20806, d: 73390\n",
      "local batches: 227 --  w: 21100, b: 20881, d: 73751\n",
      "local batches: 228 --  w: 21194, b: 20977, d: 74081\n",
      "local batches: 229 --  w: 21281, b: 21068, d: 74423\n",
      " -- global batches = 1475 --  w: 140821, b: 138239, d: 446860 (total: 725920)\n",
      "local batches: 230 --  w: 21382, b: 21169, d: 74741\n",
      "local batches: 231 --  w: 21478, b: 21265, d: 75069\n",
      "local batches: 232 --  w: 21572, b: 21352, d: 75408\n",
      "local batches: 233 --  w: 21653, b: 21455, d: 75744\n",
      "local batches: 234 --  w: 21758, b: 21535, d: 76079\n",
      " -- global batches = 1490 --  w: 142224, b: 139616, d: 451880 (total: 733720)\n",
      "local batches: 235 --  w: 21860, b: 21610, d: 76422\n",
      "local batches: 236 --  w: 21957, b: 21684, d: 76771\n",
      "local batches: 237 --  w: 22067, b: 21794, d: 77071\n",
      "local batches: 238 --  w: 22153, b: 21872, d: 77427\n",
      "local batches: 239 --  w: 22251, b: 21981, d: 77741\n",
      " -- global batches = 1505 --  w: 143672, b: 140932, d: 456917 (total: 741521)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/Philip/Desktop/GitHub/ChessEngine/Train Value Function/Monte Carlo/ValueTrain_MC_v28_ParBatched_3.ipynb Cell 6\u001b[0m line \u001b[0;36m7\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Philip/Desktop/GitHub/ChessEngine/Train%20Value%20Function/Monte%20Carlo/ValueTrain_MC_v28_ParBatched_3.ipynb#X15sZmlsZQ%3D%3D?line=67'>68</a>\u001b[0m board_batch\u001b[39m.\u001b[39mappend(board_to_tensor(game\u001b[39m.\u001b[39mpieces))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Philip/Desktop/GitHub/ChessEngine/Train%20Value%20Function/Monte%20Carlo/ValueTrain_MC_v28_ParBatched_3.ipynb#X15sZmlsZQ%3D%3D?line=68'>69</a>\u001b[0m game\u001b[39m.\u001b[39mFlipBoard()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/Philip/Desktop/GitHub/ChessEngine/Train%20Value%20Function/Monte%20Carlo/ValueTrain_MC_v28_ParBatched_3.ipynb#X15sZmlsZQ%3D%3D?line=69'>70</a>\u001b[0m \u001b[39mif\u001b[39;00m game\u001b[39m.\u001b[39;49mis_over():\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Philip/Desktop/GitHub/ChessEngine/Train%20Value%20Function/Monte%20Carlo/ValueTrain_MC_v28_ParBatched_3.ipynb#X15sZmlsZQ%3D%3D?line=70'>71</a>\u001b[0m     mate \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Philip/Desktop/GitHub/ChessEngine/Train%20Value%20Function/Monte%20Carlo/ValueTrain_MC_v28_ParBatched_3.ipynb#X15sZmlsZQ%3D%3D?line=71'>72</a>\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/GitHub/ChessEngine/Resources/Game.py:100\u001b[0m, in \u001b[0;36mGame.is_over\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[39mif\u001b[39;00m (tot \u001b[39m==\u001b[39m \u001b[39m22\u001b[39m\u001b[39m+\u001b[39m\u001b[39m2\u001b[39m \u001b[39mand\u001b[39;00m piece_counts[\u001b[39m2\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m) \u001b[39mor\u001b[39;00m (tot \u001b[39m==\u001b[39m \u001b[39m22\u001b[39m\u001b[39m+\u001b[39m\u001b[39m12\u001b[39m \u001b[39mand\u001b[39;00m piece_counts[\u001b[39m12\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[1;32m     98\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m--> 100\u001b[0m moves \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mPossibleMoves()\n\u001b[1;32m    102\u001b[0m \u001b[39m# No moves available -> stalemate or checkmate\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(moves) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m: \n",
      "File \u001b[0;32m~/Desktop/GitHub/ChessEngine/Resources/Game.py:769\u001b[0m, in \u001b[0;36mGame.PossibleMoves\u001b[0;34m(self, any)\u001b[0m\n\u001b[1;32m    767\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpieces[y, x] \u001b[39m==\u001b[39m \u001b[39m5\u001b[39m:\n\u001b[1;32m    768\u001b[0m     queens\u001b[39m.\u001b[39mappend((y, x))\n\u001b[0;32m--> 769\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpieces[y, x] \u001b[39m==\u001b[39m \u001b[39m6\u001b[39m:\n\u001b[1;32m    770\u001b[0m     king \u001b[39m=\u001b[39m (y, x)\n\u001b[1;32m    771\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpieces[y, x] \u001b[39m==\u001b[39m \u001b[39m11\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# keep generating new batches of data until stopped\n",
    "while True:\n",
    "\n",
    "    batch_white_wins = 0\n",
    "    batch_black_wins = 0\n",
    "    batch_draws = 0\n",
    "\n",
    "    # load newest model\n",
    "    model = Model_v28()\n",
    "    model_saves = os.listdir('../Monte Carlo/Model Saves MC v28')\n",
    "    if len(model_saves) > 0:\n",
    "        newest_model = max(int(i[6:-8]) for i in model_saves)\n",
    "        model.load_state_dict(torch.load('../Monte Carlo/Model Saves MC v28/model_{}_batches'.format(newest_model)))\n",
    "    else:\n",
    "        time.sleep(0.05)\n",
    "\n",
    "    # print('loaded model ', newest_model)\n",
    "\n",
    "    with open('/Users/Philip/Desktop/Projects/RL Chess/MCTS/Game Saves v28/stats', 'rb') as f:\n",
    "        stats = torch.load(f)\n",
    "    stats = stats.int()\n",
    "    global_white_wins   = stats[1]\n",
    "    global_black_wins   = stats[2]\n",
    "    global_draws        = stats[3]\n",
    "\n",
    "    if (global_white_wins + global_black_wins + global_draws) == 0:\n",
    "        percentage_decisive = 0.5\n",
    "    else:\n",
    "        percentage_decisive = ((global_white_wins + global_black_wins) / (global_white_wins + global_black_wins + global_draws)).item()\n",
    "    \n",
    "    batch_size = int(batch_target // percentage_decisive) # so that on average we have [batch_target] decisive games\n",
    "\n",
    "    meta_games = []\n",
    "    meta_boards_white = []; meta_boards_black = []\n",
    "    i = 0\n",
    "\n",
    "    meta_active = []\n",
    "\n",
    "    for game_ind in range(batch_size):\n",
    "        meta_games.append( Game() )\n",
    "        meta_boards_white.append([]); meta_boards_black.append([])\n",
    "        meta_active.append(True)\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    while True in meta_active:\n",
    "\n",
    "        i += 1\n",
    "        full_board_batch = []\n",
    "        meta_board_batch_sizes = [] # save batch sizes to split model output afterwards\n",
    "        meta_moves = []\n",
    "\n",
    "        # go through games, collect positions for value evaluations\n",
    "        for g, game in enumerate(meta_games):\n",
    "\n",
    "            if not meta_active[g]:\n",
    "                meta_board_batch_sizes.append(0)\n",
    "                meta_moves.append([])\n",
    "                continue\n",
    "\n",
    "            meta_moves.append(game.PossibleMoves())\n",
    "            game_ini = game.copy()\n",
    "            board_batch = [board_to_tensor(game.pieces)]\n",
    "            mate = False\n",
    "\n",
    "            for move in meta_moves[-1]:\n",
    "                game.PlayMove(move)\n",
    "                board_batch.append(board_to_tensor(game.pieces))\n",
    "                game.FlipBoard()\n",
    "                if game.is_over():\n",
    "                    mate = True\n",
    "                    break\n",
    "                game = game_ini.copy()\n",
    "\n",
    "            meta_games[g] = game.copy()\n",
    "\n",
    "            if mate:\n",
    "                meta_active[g] = False\n",
    "                meta_board_batch_sizes.append(0)\n",
    "                game.FlipBoard()\n",
    "                if i % 2 == 1:\n",
    "                    meta_boards_white[g].append(board_to_bool_tensor(game.pieces))\n",
    "                if i % 2 == 0:\n",
    "                    meta_boards_black[g].append(board_to_bool_tensor(game.pieces))\n",
    "\n",
    "            if not mate:\n",
    "                full_board_batch = full_board_batch + board_batch\n",
    "                meta_board_batch_sizes.append(len(board_batch))\n",
    "\n",
    "        if len(full_board_batch) == 0:\n",
    "            break\n",
    "\n",
    "        # get values of all positions\n",
    "        full_board_batch = torch.stack(full_board_batch)\n",
    "        out = model(full_board_batch).detach()\n",
    "        meta_values = torch.split(out, meta_board_batch_sizes)\n",
    "\n",
    "        # make moves for all games\n",
    "        for g, game in enumerate(meta_games):\n",
    "\n",
    "            if not meta_active[g]:\n",
    "                continue\n",
    "            values = meta_values[g]\n",
    "            values_diff = [scale(i)*(values[j] - values[0]) for j in range(1, len(values))]\n",
    "            move_prob = torch.softmax(torch.Tensor(values_diff), dim=0).numpy()\n",
    "            chosen_i = np.random.choice(range(len(meta_moves[g])), p=move_prob)\n",
    "            chosen_move = meta_moves[g][chosen_i]\n",
    "            game.PlayMove(chosen_move)\n",
    "            if i % 2 == 1:\n",
    "                meta_boards_white[g].append(board_to_bool_tensor(game.pieces))\n",
    "            if i % 2 == 0:\n",
    "                meta_boards_black[g].append(board_to_bool_tensor(game.pieces))\n",
    "            game.FlipBoard()\n",
    "\n",
    "    meta_inputs = []\n",
    "    meta_labels = []\n",
    "\n",
    "    for g, game in enumerate(meta_games):\n",
    "        \n",
    "        winner = game.get_winner()\n",
    "        if winner == 'draw':\n",
    "            draws += 1; batch_draws += 1\n",
    "            continue\n",
    "            reward_white = 0;   reward_black = 0\n",
    "\n",
    "        elif winner == 'white':\n",
    "            white_wins += 1; batch_white_wins += 1\n",
    "            reward_white = 1;   reward_black = -1\n",
    "\n",
    "        elif winner == 'black':\n",
    "            black_wins += 1; batch_black_wins += 1\n",
    "            reward_white = -1;  reward_black = 1\n",
    "\n",
    "        labels_white = [reward_white * gamma**(len(meta_boards_white[g]) - 1 - i) for i in range(len(meta_boards_white[g]))]\n",
    "        labels_black = [reward_black * gamma**(len(meta_boards_black[g]) - 1 - i) for i in range(len(meta_boards_black[g]))]\n",
    "\n",
    "        meta_inputs = meta_inputs + meta_boards_white[g] + meta_boards_black[g]\n",
    "        meta_labels = meta_labels + labels_white + labels_black\n",
    "\n",
    "    if batch_white_wins + batch_black_wins == 0:\n",
    "        print('no decisive games in the whole batch -> skip to next batch (batch size too small?)')\n",
    "        continue\n",
    "\n",
    "    inputs_tens = torch.stack(meta_inputs)\n",
    "    labels_tens = torch.Tensor(meta_labels)\n",
    "\n",
    "    with open('/Users/Philip/Desktop/Projects/RL Chess/MCTS/Game Saves v28/stats', 'rb') as f:\n",
    "        stats = torch.load(f)\n",
    "    stats = stats.int()\n",
    "    stats[0] += 1;                  stats[1] += batch_white_wins\n",
    "    stats[2] += batch_black_wins;   stats[3] += batch_draws\n",
    "    torch.save(stats, '/Users/Philip/Desktop/Projects/RL Chess/MCTS/Game Saves v28/stats')\n",
    "\n",
    "    new_batch_index = stats[0]\n",
    "    torch.save(inputs_tens, '/Users/Philip/Desktop/Projects/RL Chess/MCTS/Game Saves v28/inputs_{}'.format(new_batch_index))\n",
    "    torch.save(labels_tens, '/Users/Philip/Desktop/Projects/RL Chess/MCTS/Game Saves v28/labels_{}'.format(new_batch_index))\n",
    "\n",
    "    print('local batches: {} --  w: {}, b: {}, d: {}'.format(batch_count, white_wins, black_wins, draws))\n",
    "\n",
    "    batch_count += 1\n",
    "            \n",
    "    if batch_count % 5 == 0:\n",
    "        print(' -- global batches = {} --  w: {}, b: {}, d: {} (total: {})'.format(\n",
    "            new_batch_index, stats[1], stats[2], stats[3], stats[1] + stats[2] + stats[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
