{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import sys, os\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "sys.path.append(project_root)\n",
    "\n",
    "from Resources.Model import Model_v8\n",
    "from Resources.Game import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### global parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 0.98\n",
    "value_diff_scale = 50\n",
    "value_diff_scale_early = 1\n",
    "# games saved in batches to reduce i/o stream\n",
    "# each batch is a input file and a label file containing [batch_size] individual games\n",
    "batch_target = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### local counters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "white_wins = 0\n",
    "black_wins = 0\n",
    "draws = 0\n",
    "\n",
    "batch_count = 0         # number of batches locally done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local batches: 0 --  w: 53, b: 55, d: 142\n",
      "local batches: 1 --  w: 112, b: 100, d: 288\n",
      "local batches: 2 --  w: 166, b: 146, d: 438\n",
      "local batches: 3 --  w: 220, b: 204, d: 576\n",
      "local batches: 4 --  w: 277, b: 254, d: 719\n",
      " -- global batches = 1240 --  w: 61908, b: 62151, d: 186851 (total: 310910)\n",
      "local batches: 5 --  w: 339, b: 317, d: 844\n",
      "local batches: 6 --  w: 390, b: 362, d: 998\n",
      "local batches: 7 --  w: 440, b: 411, d: 1149\n",
      "local batches: 8 --  w: 494, b: 450, d: 1306\n",
      "local batches: 9 --  w: 556, b: 493, d: 1451\n",
      " -- global batches = 1265 --  w: 63260, b: 63400, d: 190500 (total: 317160)\n",
      "local batches: 10 --  w: 627, b: 533, d: 1590\n",
      "local batches: 11 --  w: 675, b: 583, d: 1742\n",
      "local batches: 12 --  w: 735, b: 635, d: 1880\n",
      "local batches: 13 --  w: 788, b: 693, d: 2019\n",
      "local batches: 14 --  w: 830, b: 765, d: 2154\n",
      " -- global batches = 1291 --  w: 64792, b: 64760, d: 194105 (total: 323657)\n",
      "local batches: 15 --  w: 898, b: 813, d: 2287\n",
      "local batches: 16 --  w: 938, b: 858, d: 2451\n",
      "local batches: 17 --  w: 991, b: 900, d: 2605\n",
      "local batches: 18 --  w: 1056, b: 946, d: 2743\n",
      "local batches: 19 --  w: 1124, b: 983, d: 2887\n",
      " -- global batches = 1315 --  w: 66101, b: 65909, d: 197623 (total: 329633)\n",
      "local batches: 20 --  w: 1168, b: 1018, d: 3057\n",
      "local batches: 21 --  w: 1213, b: 1071, d: 3208\n",
      "local batches: 22 --  w: 1267, b: 1120, d: 3354\n",
      "local batches: 23 --  w: 1319, b: 1155, d: 3516\n",
      "local batches: 24 --  w: 1363, b: 1202, d: 3674\n",
      " -- global batches = 1341 --  w: 67452, b: 67105, d: 201550 (total: 336107)\n",
      "local batches: 25 --  w: 1412, b: 1245, d: 3831\n",
      "local batches: 26 --  w: 1463, b: 1293, d: 3981\n",
      "local batches: 27 --  w: 1505, b: 1336, d: 4145\n",
      "local batches: 28 --  w: 1552, b: 1397, d: 4286\n",
      "local batches: 29 --  w: 1616, b: 1438, d: 4430\n",
      " -- global batches = 1366 --  w: 68736, b: 68281, d: 205315 (total: 342332)\n",
      "local batches: 30 --  w: 1658, b: 1488, d: 4587\n",
      "local batches: 31 --  w: 1707, b: 1526, d: 4749\n",
      "local batches: 32 --  w: 1759, b: 1579, d: 4893\n",
      "local batches: 33 --  w: 1815, b: 1632, d: 5033\n",
      "local batches: 34 --  w: 1861, b: 1678, d: 5190\n",
      " -- global batches = 1390 --  w: 69964, b: 69412, d: 208932 (total: 348308)\n",
      "local batches: 35 --  w: 1919, b: 1736, d: 5323\n",
      "local batches: 36 --  w: 1947, b: 1788, d: 5492\n",
      "local batches: 37 --  w: 1996, b: 1838, d: 5642\n",
      "local batches: 38 --  w: 2045, b: 1892, d: 5788\n",
      "local batches: 39 --  w: 2106, b: 1942, d: 5926\n",
      " -- global batches = 1415 --  w: 71256, b: 70695, d: 212582 (total: 354533)\n",
      "local batches: 40 --  w: 2153, b: 1983, d: 6087\n",
      "local batches: 41 --  w: 2212, b: 2031, d: 6229\n",
      "local batches: 42 --  w: 2261, b: 2087, d: 6373\n",
      "local batches: 43 --  w: 2310, b: 2148, d: 6512\n",
      "local batches: 44 --  w: 2362, b: 2197, d: 6660\n",
      " -- global batches = 1440 --  w: 72516, b: 71938, d: 216304 (total: 360758)\n",
      "local batches: 45 --  w: 2417, b: 2247, d: 6804\n",
      "local batches: 46 --  w: 2461, b: 2305, d: 6951\n",
      "local batches: 47 --  w: 2516, b: 2351, d: 7099\n",
      "local batches: 48 --  w: 2561, b: 2409, d: 7245\n",
      "local batches: 49 --  w: 2607, b: 2452, d: 7405\n",
      " -- global batches = 1464 --  w: 73738, b: 73124, d: 219872 (total: 366734)\n",
      "local batches: 50 --  w: 2667, b: 2499, d: 7547\n",
      "local batches: 51 --  w: 2708, b: 2561, d: 7693\n",
      "local batches: 52 --  w: 2773, b: 2610, d: 7828\n",
      "local batches: 53 --  w: 2836, b: 2656, d: 7968\n",
      "local batches: 54 --  w: 2890, b: 2701, d: 8118\n",
      " -- global batches = 1489 --  w: 75068, b: 74336, d: 223555 (total: 372959)\n",
      "local batches: 55 --  w: 2943, b: 2748, d: 8267\n",
      "local batches: 56 --  w: 3004, b: 2802, d: 8401\n",
      "local batches: 57 --  w: 3072, b: 2848, d: 8536\n",
      "local batches: 58 --  w: 3129, b: 2892, d: 8684\n",
      "local batches: 59 --  w: 3179, b: 2934, d: 8841\n",
      " -- global batches = 1514 --  w: 76411, b: 75649, d: 227124 (total: 379184)\n",
      "local batches: 60 --  w: 3237, b: 2986, d: 8980\n",
      "local batches: 61 --  w: 3296, b: 3037, d: 9119\n",
      "local batches: 62 --  w: 3362, b: 3081, d: 9258\n",
      "local batches: 63 --  w: 3421, b: 3142, d: 9387\n",
      "local batches: 64 --  w: 3472, b: 3185, d: 9542\n",
      " -- global batches = 1539 --  w: 77817, b: 76965, d: 230627 (total: 385409)\n",
      "local batches: 65 --  w: 3529, b: 3237, d: 9682\n",
      "local batches: 66 --  w: 3584, b: 3285, d: 9827\n",
      "local batches: 67 --  w: 3623, b: 3334, d: 9987\n",
      "local batches: 68 --  w: 3669, b: 3384, d: 10140\n",
      "local batches: 69 --  w: 3729, b: 3436, d: 10277\n",
      " -- global batches = 1564 --  w: 79084, b: 78230, d: 234304 (total: 391618)\n",
      "local batches: 70 --  w: 3776, b: 3482, d: 10432\n",
      "local batches: 71 --  w: 3824, b: 3533, d: 10581\n",
      "local batches: 72 --  w: 3852, b: 3586, d: 10748\n",
      "local batches: 73 --  w: 3906, b: 3639, d: 10889\n",
      "local batches: 74 --  w: 3944, b: 3687, d: 11051\n",
      " -- global batches = 1589 --  w: 80282, b: 79492, d: 238045 (total: 397819)\n",
      "local batches: 75 --  w: 3994, b: 3728, d: 11208\n",
      "local batches: 76 --  w: 4038, b: 3774, d: 11367\n",
      "local batches: 77 --  w: 4080, b: 3827, d: 11520\n",
      "local batches: 78 --  w: 4129, b: 3875, d: 11671\n",
      "local batches: 79 --  w: 4178, b: 3933, d: 11812\n",
      " -- global batches = 1614 --  w: 81517, b: 80766, d: 241741 (total: 404024)\n",
      "local batches: 80 --  w: 4229, b: 3993, d: 11949\n",
      "local batches: 81 --  w: 4283, b: 4044, d: 12092\n",
      "local batches: 82 --  w: 4332, b: 4096, d: 12239\n",
      "local batches: 83 --  w: 4389, b: 4159, d: 12367\n",
      "local batches: 84 --  w: 4432, b: 4222, d: 12509\n",
      " -- global batches = 1639 --  w: 82809, b: 82255, d: 245160 (total: 410224)\n",
      "local batches: 85 --  w: 4492, b: 4280, d: 12639\n",
      "local batches: 86 --  w: 4559, b: 4334, d: 12766\n",
      "local batches: 87 --  w: 4617, b: 4401, d: 12889\n",
      "local batches: 88 --  w: 4664, b: 4456, d: 13035\n",
      "local batches: 89 --  w: 4710, b: 4517, d: 13176\n",
      " -- global batches = 1663 --  w: 84059, b: 83640, d: 248477 (total: 416176)\n",
      "local batches: 90 --  w: 4758, b: 4560, d: 13333\n",
      "local batches: 91 --  w: 4816, b: 4617, d: 13466\n",
      "local batches: 92 --  w: 4859, b: 4681, d: 13607\n",
      "local batches: 93 --  w: 4915, b: 4738, d: 13742\n",
      "local batches: 94 --  w: 4969, b: 4797, d: 13877\n",
      " -- global batches = 1688 --  w: 85289, b: 85019, d: 252068 (total: 422376)\n",
      "local batches: 95 --  w: 5021, b: 4856, d: 14014\n",
      "local batches: 96 --  w: 5075, b: 4908, d: 14155\n",
      "local batches: 97 --  w: 5134, b: 4953, d: 14298\n",
      "local batches: 98 --  w: 5178, b: 5010, d: 14444\n",
      "local batches: 99 --  w: 5243, b: 5063, d: 14573\n",
      " -- global batches = 1713 --  w: 86625, b: 86400, d: 255531 (total: 428556)\n",
      "local batches: 100 --  w: 5287, b: 5114, d: 14725\n",
      "local batches: 101 --  w: 5339, b: 5173, d: 14861\n",
      "local batches: 102 --  w: 5382, b: 5221, d: 15017\n",
      "local batches: 103 --  w: 5439, b: 5269, d: 15159\n",
      "local batches: 104 --  w: 5496, b: 5322, d: 15296\n",
      " -- global batches = 1739 --  w: 87956, b: 87851, d: 259171 (total: 434978)\n",
      "local batches: 105 --  w: 5548, b: 5372, d: 15441\n",
      "local batches: 106 --  w: 5598, b: 5431, d: 15579\n",
      "local batches: 107 --  w: 5654, b: 5489, d: 15712\n",
      "local batches: 108 --  w: 5703, b: 5545, d: 15854\n",
      "local batches: 109 --  w: 5763, b: 5593, d: 15993\n",
      " -- global batches = 1765 --  w: 89393, b: 89256, d: 262751 (total: 441400)\n",
      "local batches: 110 --  w: 5811, b: 5639, d: 16146\n",
      "local batches: 111 --  w: 5860, b: 5691, d: 16292\n",
      "local batches: 112 --  w: 5895, b: 5759, d: 16435\n",
      "local batches: 113 --  w: 5943, b: 5824, d: 16568\n",
      "local batches: 114 --  w: 5994, b: 5891, d: 16696\n",
      " -- global batches = 1790 --  w: 90594, b: 90719, d: 266248 (total: 447561)\n",
      "local batches: 115 --  w: 6047, b: 5947, d: 16833\n",
      "local batches: 116 --  w: 6099, b: 6009, d: 16965\n",
      "local batches: 117 --  w: 6150, b: 6059, d: 17110\n",
      "local batches: 118 --  w: 6213, b: 6109, d: 17243\n",
      "local batches: 119 --  w: 6271, b: 6169, d: 17371\n",
      " -- global batches = 1815 --  w: 91942, b: 92129, d: 269640 (total: 453711)\n",
      "local batches: 120 --  w: 6319, b: 6227, d: 17511\n",
      "local batches: 121 --  w: 6376, b: 6285, d: 17642\n",
      "local batches: 122 --  w: 6437, b: 6339, d: 17773\n",
      "local batches: 123 --  w: 6507, b: 6393, d: 17895\n",
      "local batches: 124 --  w: 6572, b: 6456, d: 18013\n",
      " -- global batches = 1840 --  w: 93353, b: 93555, d: 272953 (total: 459861)\n",
      "local batches: 125 --  w: 6621, b: 6515, d: 18151\n",
      "local batches: 126 --  w: 6675, b: 6560, d: 18297\n",
      "local batches: 127 --  w: 6725, b: 6614, d: 18438\n",
      "local batches: 128 --  w: 6786, b: 6678, d: 18558\n",
      "local batches: 129 --  w: 6837, b: 6734, d: 18696\n",
      " -- global batches = 1865 --  w: 94707, b: 94921, d: 276365 (total: 465993)\n",
      "local batches: 130 --  w: 6893, b: 6788, d: 18831\n",
      "local batches: 131 --  w: 6945, b: 6841, d: 18971\n",
      "local batches: 132 --  w: 7012, b: 6890, d: 19100\n",
      "local batches: 133 --  w: 7062, b: 6942, d: 19243\n",
      "local batches: 134 --  w: 7112, b: 6994, d: 19386\n",
      " -- global batches = 1890 --  w: 96120, b: 96220, d: 279778 (total: 472118)\n",
      "local batches: 135 --  w: 7174, b: 7038, d: 19525\n",
      "local batches: 136 --  w: 7227, b: 7079, d: 19676\n",
      "local batches: 137 --  w: 7275, b: 7140, d: 19812\n",
      "local batches: 138 --  w: 7324, b: 7207, d: 19941\n",
      "local batches: 139 --  w: 7382, b: 7262, d: 20073\n",
      " -- global batches = 1914 --  w: 97357, b: 97530, d: 283111 (total: 477998)\n",
      "local batches: 140 --  w: 7445, b: 7318, d: 20199\n",
      "local batches: 141 --  w: 7500, b: 7368, d: 20339\n",
      "local batches: 142 --  w: 7556, b: 7426, d: 20470\n",
      "local batches: 143 --  w: 7613, b: 7476, d: 20608\n",
      "local batches: 144 --  w: 7686, b: 7515, d: 20741\n",
      " -- global batches = 1939 --  w: 98763, b: 98856, d: 286504 (total: 484123)\n",
      "local batches: 145 --  w: 7741, b: 7571, d: 20874\n",
      "local batches: 146 --  w: 7802, b: 7625, d: 21003\n",
      "local batches: 147 --  w: 7868, b: 7688, d: 21118\n",
      "local batches: 148 --  w: 7922, b: 7737, d: 21259\n",
      "local batches: 149 --  w: 7977, b: 7790, d: 21395\n",
      " -- global batches = 1964 --  w: 100206, b: 100239, d: 289781 (total: 490226)\n",
      "local batches: 150 --  w: 8038, b: 7852, d: 21516\n",
      "local batches: 151 --  w: 8091, b: 7901, d: 21658\n",
      "local batches: 152 --  w: 8141, b: 7949, d: 21804\n",
      "local batches: 153 --  w: 8193, b: 8009, d: 21936\n",
      "local batches: 154 --  w: 8251, b: 8077, d: 22054\n",
      " -- global batches = 1989 --  w: 101649, b: 101685, d: 292992 (total: 496326)\n",
      "local batches: 155 --  w: 8314, b: 8121, d: 22191\n",
      "local batches: 156 --  w: 8381, b: 8166, d: 22322\n",
      "local batches: 157 --  w: 8440, b: 8227, d: 22445\n",
      "local batches: 158 --  w: 8501, b: 8289, d: 22565\n",
      "local batches: 159 --  w: 8554, b: 8343, d: 22701\n",
      " -- global batches = 2014 --  w: 103136, b: 103060, d: 296213 (total: 502409)\n",
      "local batches: 160 --  w: 8614, b: 8397, d: 22830\n",
      "local batches: 161 --  w: 8663, b: 8464, d: 22957\n",
      "local batches: 162 --  w: 8721, b: 8514, d: 23092\n",
      "local batches: 163 --  w: 8778, b: 8565, d: 23227\n",
      "local batches: 164 --  w: 8831, b: 8630, d: 23352\n",
      " -- global batches = 2039 --  w: 104553, b: 104420, d: 299511 (total: 508484)\n",
      "local batches: 165 --  w: 8884, b: 8687, d: 23485\n",
      "local batches: 166 --  w: 8931, b: 8755, d: 23613\n",
      "local batches: 167 --  w: 8987, b: 8797, d: 23758\n",
      "local batches: 168 --  w: 9034, b: 8848, d: 23903\n",
      "local batches: 169 --  w: 9077, b: 8906, d: 24045\n",
      " -- global batches = 2064 --  w: 105886, b: 105756, d: 302917 (total: 514559)\n",
      "local batches: 170 --  w: 9142, b: 8962, d: 24167\n",
      "local batches: 171 --  w: 9196, b: 9022, d: 24296\n",
      "local batches: 172 --  w: 9257, b: 9081, d: 24418\n",
      "local batches: 173 --  w: 9318, b: 9135, d: 24545\n",
      "local batches: 174 --  w: 9383, b: 9189, d: 24668\n",
      " -- global batches = 2088 --  w: 107334, b: 107063, d: 305984 (total: 520381)\n",
      "local batches: 175 --  w: 9436, b: 9238, d: 24808\n",
      "local batches: 176 --  w: 9481, b: 9288, d: 24955\n",
      "local batches: 177 --  w: 9540, b: 9335, d: 25091\n",
      "local batches: 178 --  w: 9593, b: 9386, d: 25229\n",
      "local batches: 179 --  w: 9652, b: 9443, d: 25355\n",
      " -- global batches = 2113 --  w: 108662, b: 108398, d: 309371 (total: 526431)\n",
      "local batches: 180 --  w: 9713, b: 9507, d: 25472\n",
      "local batches: 181 --  w: 9778, b: 9558, d: 25598\n",
      "local batches: 182 --  w: 9834, b: 9610, d: 25732\n",
      "local batches: 183 --  w: 9881, b: 9666, d: 25871\n",
      "local batches: 184 --  w: 9922, b: 9721, d: 26017\n",
      " -- global batches = 2138 --  w: 110033, b: 109738, d: 312710 (total: 532481)\n",
      "local batches: 185 --  w: 9977, b: 9780, d: 26145\n",
      "local batches: 186 --  w: 10036, b: 9842, d: 26266\n",
      "local batches: 187 --  w: 10081, b: 9900, d: 26405\n",
      "local batches: 188 --  w: 10135, b: 9953, d: 26540\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/Philip/Desktop/GitHub/ChessEngine/Train Value Function/Monte Carlo/ValueTrain_MC_v8_ParBatched_4.ipynb Cell 6\u001b[0m line \u001b[0;36m7\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Philip/Desktop/GitHub/ChessEngine/Train%20Value%20Function/Monte%20Carlo/ValueTrain_MC_v8_ParBatched_4.ipynb#W5sZmlsZQ%3D%3D?line=68'>69</a>\u001b[0m board_batch\u001b[39m.\u001b[39mappend(board_to_tensor(game\u001b[39m.\u001b[39mpieces))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Philip/Desktop/GitHub/ChessEngine/Train%20Value%20Function/Monte%20Carlo/ValueTrain_MC_v8_ParBatched_4.ipynb#W5sZmlsZQ%3D%3D?line=69'>70</a>\u001b[0m game\u001b[39m.\u001b[39mFlipBoard()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/Philip/Desktop/GitHub/ChessEngine/Train%20Value%20Function/Monte%20Carlo/ValueTrain_MC_v8_ParBatched_4.ipynb#W5sZmlsZQ%3D%3D?line=70'>71</a>\u001b[0m \u001b[39mif\u001b[39;00m game\u001b[39m.\u001b[39;49mis_over():\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Philip/Desktop/GitHub/ChessEngine/Train%20Value%20Function/Monte%20Carlo/ValueTrain_MC_v8_ParBatched_4.ipynb#W5sZmlsZQ%3D%3D?line=71'>72</a>\u001b[0m     mate \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Philip/Desktop/GitHub/ChessEngine/Train%20Value%20Function/Monte%20Carlo/ValueTrain_MC_v8_ParBatched_4.ipynb#W5sZmlsZQ%3D%3D?line=72'>73</a>\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/GitHub/ChessEngine/Resources/Game.py:100\u001b[0m, in \u001b[0;36mGame.is_over\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[39mif\u001b[39;00m (tot \u001b[39m==\u001b[39m \u001b[39m22\u001b[39m\u001b[39m+\u001b[39m\u001b[39m2\u001b[39m \u001b[39mand\u001b[39;00m piece_counts[\u001b[39m2\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m) \u001b[39mor\u001b[39;00m (tot \u001b[39m==\u001b[39m \u001b[39m22\u001b[39m\u001b[39m+\u001b[39m\u001b[39m12\u001b[39m \u001b[39mand\u001b[39;00m piece_counts[\u001b[39m12\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[1;32m     98\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m--> 100\u001b[0m moves \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mPossibleMoves()\n\u001b[1;32m    102\u001b[0m \u001b[39m# No moves available -> stalemate or checkmate\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(moves) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m: \n",
      "File \u001b[0;32m~/Desktop/GitHub/ChessEngine/Resources/Game.py:929\u001b[0m, in \u001b[0;36mGame.PossibleMoves\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    926\u001b[0m diag_down   \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m \u001b[39mif\u001b[39;00m king[\u001b[39m0\u001b[39m]\u001b[39m-\u001b[39mking[\u001b[39m1\u001b[39m] \u001b[39m==\u001b[39m move[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m]\u001b[39m-\u001b[39mmove[\u001b[39m0\u001b[39m][\u001b[39m1\u001b[39m] \u001b[39melse\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    927\u001b[0m diag_up     \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m \u001b[39mif\u001b[39;00m king[\u001b[39m0\u001b[39m]\u001b[39m+\u001b[39mking[\u001b[39m1\u001b[39m] \u001b[39m==\u001b[39m move[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m]\u001b[39m+\u001b[39mmove[\u001b[39m0\u001b[39m][\u001b[39m1\u001b[39m] \u001b[39melse\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m--> 929\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (row \u001b[39mor\u001b[39;00m column \u001b[39mor\u001b[39;00m diag_down \u001b[39mor\u001b[39;00m diag_up) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m incheck_before: \u001b[39m# move[0] shares no line with king -> certainly playable\u001b[39;00m\n\u001b[1;32m    930\u001b[0m     playable \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    932\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m playable: \n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# keep generating new batches of data until stopped\n",
    "while True:\n",
    "\n",
    "    batch_white_wins = 0\n",
    "    batch_black_wins = 0\n",
    "    batch_draws = 0\n",
    "\n",
    "    # load newest model\n",
    "    model = Model_v8()\n",
    "    model_saves = os.listdir('../Monte Carlo/Model Saves MC v8_3')\n",
    "    if len(model_saves) > 0:\n",
    "        newest_model = max(int(i[6:-8]) for i in model_saves)\n",
    "        model.load_state_dict(torch.load('../Monte Carlo/Model Saves MC v8_3/model_{}_batches'.format(newest_model)))\n",
    "    else:\n",
    "        time.sleep(0.05)\n",
    "\n",
    "    # print('loaded model ', newest_model)\n",
    "\n",
    "    with open('/Users/Philip/Desktop/Projects/RL Chess/MCTS/Game Saves v8_3/stats', 'rb') as f:\n",
    "        stats = torch.load(f)\n",
    "    stats = stats.int()\n",
    "    global_white_wins   = stats[1]\n",
    "    global_black_wins   = stats[2]\n",
    "    global_draws        = stats[3]\n",
    "\n",
    "    percentage_decisive = (global_white_wins + global_black_wins) / (global_white_wins + global_black_wins + global_draws)\n",
    "    batch_size = int(batch_target // percentage_decisive.item()) # so that on average we have [batch_target] decisive games\n",
    "\n",
    "    meta_games = []\n",
    "    meta_boards_white = []; meta_boards_black = []\n",
    "    i = 0\n",
    "\n",
    "    meta_active = []\n",
    "\n",
    "    for game_ind in range(batch_size):\n",
    "        meta_games.append( Game() )\n",
    "        meta_boards_white.append([]); meta_boards_black.append([])\n",
    "        meta_active.append(True)\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    # print('start with {} games'.format(batch_size))\n",
    "\n",
    "    while True in meta_active:\n",
    "\n",
    "        # if i % 20 == 0:\n",
    "        #     print('i = {}, with {} active games '.format(i, meta_active.count(True)))\n",
    "\n",
    "        i += 1\n",
    "        full_board_batch = []\n",
    "        meta_board_batch_sizes = [] # save batch sizes to split model output afterwards\n",
    "        meta_moves = []\n",
    "\n",
    "        # go through games, collect positions for value evaluations\n",
    "        for g, game in enumerate(meta_games):\n",
    "\n",
    "            if not meta_active[g]:\n",
    "                meta_board_batch_sizes.append(0)\n",
    "                meta_moves.append([])\n",
    "                continue\n",
    "\n",
    "            meta_moves.append(game.PossibleMoves())\n",
    "            game_ini = game.copy()\n",
    "            board_batch = [board_to_tensor(game.pieces)]\n",
    "            mate = False\n",
    "\n",
    "            for move in meta_moves[-1]:\n",
    "                game.PlayMove(move)\n",
    "                board_batch.append(board_to_tensor(game.pieces))\n",
    "                game.FlipBoard()\n",
    "                if game.is_over():\n",
    "                    mate = True\n",
    "                    break\n",
    "                game = game_ini.copy()\n",
    "\n",
    "            meta_games[g] = game.copy()\n",
    "\n",
    "            if mate:\n",
    "                meta_active[g] = False\n",
    "                meta_board_batch_sizes.append(0)\n",
    "                game.FlipBoard()\n",
    "                if i % 2 == 1:\n",
    "                    meta_boards_white[g].append(board_to_bool_tensor(game.pieces))\n",
    "                if i % 2 == 0:\n",
    "                    meta_boards_black[g].append(board_to_bool_tensor(game.pieces))\n",
    "\n",
    "            if not mate:\n",
    "                full_board_batch = full_board_batch + board_batch\n",
    "                meta_board_batch_sizes.append(len(board_batch))\n",
    "\n",
    "        if len(full_board_batch) == 0:\n",
    "            break\n",
    "\n",
    "        # get values of all positions\n",
    "        full_board_batch = torch.stack(full_board_batch)\n",
    "        out = model(full_board_batch).detach()\n",
    "        meta_values = torch.split(out, meta_board_batch_sizes)\n",
    "\n",
    "        # make moves for all games\n",
    "        for g, game in enumerate(meta_games):\n",
    "\n",
    "            if not meta_active[g]:\n",
    "                continue\n",
    "            values = meta_values[g]\n",
    "            if i < 7:\n",
    "                scale = value_diff_scale_early\n",
    "            else:\n",
    "                scale = value_diff_scale\n",
    "            values_diff = [scale*(values[i] - values[0]) for i in range(1, len(values))]\n",
    "            move_prob = torch.softmax(torch.Tensor(values_diff), dim=0).numpy()\n",
    "            chosen_i = np.random.choice(range(len(meta_moves[g])), p=move_prob)\n",
    "            chosen_move = meta_moves[g][chosen_i]\n",
    "            game.PlayMove(chosen_move)\n",
    "            if i % 2 == 1:\n",
    "                meta_boards_white[g].append(board_to_bool_tensor(game.pieces))\n",
    "            if i % 2 == 0:\n",
    "                meta_boards_black[g].append(board_to_bool_tensor(game.pieces))\n",
    "            game.FlipBoard()\n",
    "\n",
    "    # print('games done, start evaluating')\n",
    "\n",
    "    meta_inputs = []\n",
    "    meta_labels = []\n",
    "\n",
    "    for g, game in enumerate(meta_games):\n",
    "        \n",
    "        winner = game.get_winner()\n",
    "        if winner == 'draw':\n",
    "            draws += 1; batch_draws += 1\n",
    "            continue\n",
    "            reward_white = 0;   reward_black = 0\n",
    "\n",
    "        elif winner == 'white':\n",
    "            white_wins += 1; batch_white_wins += 1\n",
    "            reward_white = 1;   reward_black = -1\n",
    "\n",
    "        elif winner == 'black':\n",
    "            black_wins += 1; batch_black_wins += 1\n",
    "            reward_white = -1;  reward_black = 1\n",
    "\n",
    "        labels_white = [reward_white * gamma**(len(meta_boards_white[g]) - 1 - i) for i in range(len(meta_boards_white[g]))]\n",
    "        labels_black = [reward_black * gamma**(len(meta_boards_black[g]) - 1 - i) for i in range(len(meta_boards_black[g]))]\n",
    "\n",
    "        meta_inputs = meta_inputs + meta_boards_white[g] + meta_boards_black[g]\n",
    "        meta_labels = meta_labels + labels_white + labels_black\n",
    "\n",
    "    if batch_white_wins + batch_black_wins == 0:\n",
    "        print('no decisive games in the whole batch -> skip to next batch (batch size too small?)')\n",
    "        continue\n",
    "\n",
    "    inputs_tens = torch.stack(meta_inputs)\n",
    "    labels_tens = torch.Tensor(meta_labels)\n",
    "\n",
    "    # print('evaluation done, save batch')\n",
    "\n",
    "    with open('/Users/Philip/Desktop/Projects/RL Chess/MCTS/Game Saves v8_3/stats', 'rb') as f:\n",
    "        stats = torch.load(f)\n",
    "    stats = stats.int()\n",
    "    stats[0] += 1;                  stats[1] += batch_white_wins\n",
    "    stats[2] += batch_black_wins;   stats[3] += batch_draws\n",
    "    torch.save(stats, '/Users/Philip/Desktop/Projects/RL Chess/MCTS/Game Saves v8_3/stats')\n",
    "\n",
    "    # print('batch index = ', stats[0])\n",
    "\n",
    "    new_batch_index = stats[0]\n",
    "    torch.save(inputs_tens, '/Users/Philip/Desktop/Projects/RL Chess/MCTS/Game Saves v8_3/inputs_{}'.format(new_batch_index))\n",
    "    torch.save(labels_tens, '/Users/Philip/Desktop/Projects/RL Chess/MCTS/Game Saves v8_3/labels_{}'.format(new_batch_index))\n",
    "\n",
    "    print('local batches: {} --  w: {}, b: {}, d: {}'.format(batch_count, white_wins, black_wins, draws))\n",
    "\n",
    "    batch_count += 1\n",
    "\n",
    "    if batch_count % 5 == 0:\n",
    "        print(' -- global batches = {} --  w: {}, b: {}, d: {} (total: {})'.format(\n",
    "            new_batch_index, stats[1], stats[2], stats[3], stats[1] + stats[2] + stats[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
